{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "037ba7d5-e9c1-490f-8f7c-6c7338e6d5ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.optim import AdamW, lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from utils.data import GeneFeatureDataset, seq_concat, select_cols\n",
    "from utils.model import GeneInteractionModel\n",
    "from utils.loss import BalancedMSELoss\n",
    "\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from itertools import combinations\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a4e862cf-732e-4e84-94f3-cab49b0aae9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f258800-b651-4bd5-a839-96788ee034ad",
   "metadata": {},
   "source": [
    "# Create test/train splits for 5 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0ac3127b-8768-43da-b963-8a135dfcda38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene</th>\n",
       "      <th>ID</th>\n",
       "      <th>WT74_On</th>\n",
       "      <th>Edited74_On</th>\n",
       "      <th>PBSlen</th>\n",
       "      <th>RTlen</th>\n",
       "      <th>RT-PBSlen</th>\n",
       "      <th>Edit_pos</th>\n",
       "      <th>Edit_len</th>\n",
       "      <th>RHA_len</th>\n",
       "      <th>...</th>\n",
       "      <th>nGCcnt1</th>\n",
       "      <th>nGCcnt2</th>\n",
       "      <th>nGCcnt3</th>\n",
       "      <th>fGCcont1</th>\n",
       "      <th>fGCcont2</th>\n",
       "      <th>fGCcont3</th>\n",
       "      <th>MFE3</th>\n",
       "      <th>MFE4</th>\n",
       "      <th>DeepSpCas9_score</th>\n",
       "      <th>Measured_PE_efficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNMT1</td>\n",
       "      <td>EDFIG5B_DNMT1_10NT</td>\n",
       "      <td>TGGGGATTCCTGGTGCCAGAAACAGGGGTGACGGGAGGGCAGAACT...</td>\n",
       "      <td>xxxxxxxxCCTGGTGCCAGAAACAGTGGTxxxxxxxxxxxxxxxxx...</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>57.142857</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>65.144363</td>\n",
       "      <td>6.410003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DNMT1</td>\n",
       "      <td>EDFIG5B_DNMT1_10NT</td>\n",
       "      <td>TGGGGATTCCTGGTGCCAGAAACAGGGGTGACGGGAGGGCAGAACT...</td>\n",
       "      <td>xxxxxxxxCCTGGTGCCAGAAACAGTGGTGxxxxxxxxxxxxxxxx...</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>59.090909</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>65.144363</td>\n",
       "      <td>0.919506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DNMT1</td>\n",
       "      <td>EDFIG5B_DNMT1_10NT</td>\n",
       "      <td>TGGGGATTCCTGGTGCCAGAAACAGGGGTGACGGGAGGGCAGAACT...</td>\n",
       "      <td>xxxxxxxxCCTGGTGCCAGAAACAGTGGTGAxxxxxxxxxxxxxxx...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>56.521739</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>65.144363</td>\n",
       "      <td>5.100177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DNMT1</td>\n",
       "      <td>EDFIG5B_DNMT1_10NT</td>\n",
       "      <td>TGGGGATTCCTGGTGCCAGAAACAGGGGTGACGGGAGGGCAGAACT...</td>\n",
       "      <td>xxxxxxxxCCTGGTGCCAGAAACAGTGGTGACxxxxxxxxxxxxxx...</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>58.333333</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>65.144363</td>\n",
       "      <td>9.992335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DNMT1</td>\n",
       "      <td>EDFIG5B_DNMT1_10NT</td>\n",
       "      <td>TGGGGATTCCTGGTGCCAGAAACAGGGGTGACGGGAGGGCAGAACT...</td>\n",
       "      <td>xxxxxxxxCCTGGTGCCAGAAACAGTGGTGACGxxxxxxxxxxxxx...</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>58.333333</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>65.144363</td>\n",
       "      <td>3.479796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>RNF2</td>\n",
       "      <td>FIG2A_PE2_RNF2_10</td>\n",
       "      <td>GGCAGTCATCTTAGTCATTACCTGAGGTGTTCGTTGTAACTCATAT...</td>\n",
       "      <td>xxxxxxCATCTTAGTCATTACATGAGGTGTTCxxxxxxxxxxxxxx...</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>45.454545</td>\n",
       "      <td>38.461538</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.229725</td>\n",
       "      <td>3.630080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>RNF2</td>\n",
       "      <td>FIG2A_PE2_RNF2_10</td>\n",
       "      <td>GGCAGTCATCTTAGTCATTACCTGAGGTGTTCGTTGTAACTCATAT...</td>\n",
       "      <td>xxxxxxCATCTTAGTCATTACATGAGGTGTTCxxxxxxxxxxxxxx...</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>45.454545</td>\n",
       "      <td>38.461538</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.229725</td>\n",
       "      <td>6.989605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>RNF2</td>\n",
       "      <td>FIG2A_PE2_RNF2_10</td>\n",
       "      <td>GGCAGTCATCTTAGTCATTACCTGAGGTGTTCGTTGTAACTCATAT...</td>\n",
       "      <td>xxxxxTCATCTTAGTCATTACATGAGGTGTTCxxxxxxxxxxxxxx...</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>31.250000</td>\n",
       "      <td>45.454545</td>\n",
       "      <td>37.037037</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.229725</td>\n",
       "      <td>3.022388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>RNF2</td>\n",
       "      <td>FIG2A_PE2_RNF2_10</td>\n",
       "      <td>GGCAGTCATCTTAGTCATTACCTGAGGTGTTCGTTGTAACTCATAT...</td>\n",
       "      <td>xxxxGTCATCTTAGTCATTACATGAGGTGTTCxxxxxxxxxxxxxx...</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>35.294118</td>\n",
       "      <td>45.454545</td>\n",
       "      <td>39.285714</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.229725</td>\n",
       "      <td>2.146368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>RNF2</td>\n",
       "      <td>FIG2A_PE2_RNF2_10</td>\n",
       "      <td>GGCAGTCATCTTAGTCATTACCTGAGGTGTTCGTTGTAACTCATAT...</td>\n",
       "      <td>xxxxxxCATCTTAGTCATTACATGAGGTGTTxxxxxxxxxxxxxxx...</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.229725</td>\n",
       "      <td>6.623650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gene                  ID  \\\n",
       "0    DNMT1  EDFIG5B_DNMT1_10NT   \n",
       "1    DNMT1  EDFIG5B_DNMT1_10NT   \n",
       "2    DNMT1  EDFIG5B_DNMT1_10NT   \n",
       "3    DNMT1  EDFIG5B_DNMT1_10NT   \n",
       "4    DNMT1  EDFIG5B_DNMT1_10NT   \n",
       "..     ...                 ...   \n",
       "194   RNF2   FIG2A_PE2_RNF2_10   \n",
       "195   RNF2   FIG2A_PE2_RNF2_10   \n",
       "196   RNF2   FIG2A_PE2_RNF2_10   \n",
       "197   RNF2   FIG2A_PE2_RNF2_10   \n",
       "198   RNF2   FIG2A_PE2_RNF2_10   \n",
       "\n",
       "                                               WT74_On  \\\n",
       "0    TGGGGATTCCTGGTGCCAGAAACAGGGGTGACGGGAGGGCAGAACT...   \n",
       "1    TGGGGATTCCTGGTGCCAGAAACAGGGGTGACGGGAGGGCAGAACT...   \n",
       "2    TGGGGATTCCTGGTGCCAGAAACAGGGGTGACGGGAGGGCAGAACT...   \n",
       "3    TGGGGATTCCTGGTGCCAGAAACAGGGGTGACGGGAGGGCAGAACT...   \n",
       "4    TGGGGATTCCTGGTGCCAGAAACAGGGGTGACGGGAGGGCAGAACT...   \n",
       "..                                                 ...   \n",
       "194  GGCAGTCATCTTAGTCATTACCTGAGGTGTTCGTTGTAACTCATAT...   \n",
       "195  GGCAGTCATCTTAGTCATTACCTGAGGTGTTCGTTGTAACTCATAT...   \n",
       "196  GGCAGTCATCTTAGTCATTACCTGAGGTGTTCGTTGTAACTCATAT...   \n",
       "197  GGCAGTCATCTTAGTCATTACCTGAGGTGTTCGTTGTAACTCATAT...   \n",
       "198  GGCAGTCATCTTAGTCATTACCTGAGGTGTTCGTTGTAACTCATAT...   \n",
       "\n",
       "                                           Edited74_On  PBSlen  RTlen  \\\n",
       "0    xxxxxxxxCCTGGTGCCAGAAACAGTGGTxxxxxxxxxxxxxxxxx...      13      8   \n",
       "1    xxxxxxxxCCTGGTGCCAGAAACAGTGGTGxxxxxxxxxxxxxxxx...      13      9   \n",
       "2    xxxxxxxxCCTGGTGCCAGAAACAGTGGTGAxxxxxxxxxxxxxxx...      13     10   \n",
       "3    xxxxxxxxCCTGGTGCCAGAAACAGTGGTGACxxxxxxxxxxxxxx...      13     11   \n",
       "4    xxxxxxxxCCTGGTGCCAGAAACAGTGGTGACGxxxxxxxxxxxxx...      13     12   \n",
       "..                                                 ...     ...    ...   \n",
       "194  xxxxxxCATCTTAGTCATTACATGAGGTGTTCxxxxxxxxxxxxxx...      15     11   \n",
       "195  xxxxxxCATCTTAGTCATTACATGAGGTGTTCxxxxxxxxxxxxxx...      15     11   \n",
       "196  xxxxxTCATCTTAGTCATTACATGAGGTGTTCxxxxxxxxxxxxxx...      16     11   \n",
       "197  xxxxGTCATCTTAGTCATTACATGAGGTGTTCxxxxxxxxxxxxxx...      17     11   \n",
       "198  xxxxxxCATCTTAGTCATTACATGAGGTGTTxxxxxxxxxxxxxxx...      15     10   \n",
       "\n",
       "     RT-PBSlen  Edit_pos  Edit_len  RHA_len  ...  nGCcnt1  nGCcnt2  nGCcnt3  \\\n",
       "0           21         5         1        3  ...        8        4       12   \n",
       "1           22         5         1        4  ...        8        5       13   \n",
       "2           23         5         1        5  ...        8        5       13   \n",
       "3           24         5         1        6  ...        8        6       14   \n",
       "4           25         5         1        7  ...        8        7       15   \n",
       "..         ...       ...       ...      ...  ...      ...      ...      ...   \n",
       "194         26         1         1       10  ...        5        5       10   \n",
       "195         26         1         1       10  ...        5        5       10   \n",
       "196         27         1         1       10  ...        5        5       10   \n",
       "197         28         1         1       10  ...        6        5       11   \n",
       "198         25         1         1        9  ...        5        4        9   \n",
       "\n",
       "      fGCcont1   fGCcont2   fGCcont3  MFE3  MFE4  DeepSpCas9_score  \\\n",
       "0    61.538462  50.000000  57.142857  -1.7  -1.6         65.144363   \n",
       "1    61.538462  55.555556  59.090909  -1.7  -1.6         65.144363   \n",
       "2    61.538462  50.000000  56.521739  -1.7  -1.6         65.144363   \n",
       "3    61.538462  54.545455  58.333333  -1.7  -1.6         65.144363   \n",
       "4    61.538462  58.333333  60.000000  -1.7  -1.6         65.144363   \n",
       "..         ...        ...        ...   ...   ...               ...   \n",
       "194  33.333333  45.454545  38.461538  -1.1   0.0         52.229725   \n",
       "195  33.333333  45.454545  38.461538  -1.1   0.0         52.229725   \n",
       "196  31.250000  45.454545  37.037037  -1.6   0.0         52.229725   \n",
       "197  35.294118  45.454545  39.285714  -1.5   0.0         52.229725   \n",
       "198  33.333333  40.000000  36.000000  -0.2   0.0         52.229725   \n",
       "\n",
       "     Measured_PE_efficiency  \n",
       "0                  6.410003  \n",
       "1                  0.919506  \n",
       "2                  5.100177  \n",
       "3                  9.992335  \n",
       "4                  3.479796  \n",
       "..                      ...  \n",
       "194                3.630080  \n",
       "195                6.989605  \n",
       "196                3.022388  \n",
       "197                2.146368  \n",
       "198                6.623650  \n",
       "\n",
       "[199 rows x 29 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_data = pd.read_csv('../easy_prime/figure_rep/DeepPrime_ForFT_withGenes.csv')\n",
    "finetune_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38404d05-9baf-4a5b-8b5f-f6018444f118",
   "metadata": {},
   "source": [
    "### At the end of this section, you have 5 different splits of test/train data. In each of the test sets, there is roughly equal representation across all the 8 genes. Additionally, if you concatenate all the test sets together across all 5 models, you will get all the 199 points. Additionally, each test/train pair contains all 199 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "62d94fe7-aa16-4840-97e6-698fc3842ab9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159 40\n",
      "159 40\n",
      "159 40\n",
      "159 40\n",
      "160 39\n"
     ]
    }
   ],
   "source": [
    "genes = ['RNF2', 'EMX1', 'VEGFA', 'HEK3', 'FANCF', 'DNMT1', 'HEK4', 'RUNX1']\n",
    "\n",
    "# Define the number of splits\n",
    "num_splits = 5\n",
    "\n",
    "# Initialize StratifiedKFold to ensure balanced splitting\n",
    "skf = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Combine all gene indices into a single list\n",
    "all_gene_indices = np.concatenate(list(gene_indices.values()))\n",
    "\n",
    "\n",
    "# Create labels for each gene based on their indices\n",
    "gene_labels = np.zeros(len(all_gene_indices))\n",
    "for i, gene_name in enumerate(gene_indices.keys()):\n",
    "    gene_labels[gene_indices[gene_name]] = i\n",
    "\n",
    "# List to store train/test splits\n",
    "train_test_splits = []\n",
    "\n",
    "# Iterate over the splits\n",
    "for train_index, test_index in skf.split(all_gene_indices, gene_labels):\n",
    "    # Initialize lists to store indices for train and test sets\n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "    \n",
    "    # Split each gene's data separately\n",
    "    for gene_name, indices in gene_indices.items():\n",
    "        \n",
    "        # Divide the indices into train and test sets\n",
    "        gene_train_index = np.intersect1d(train_index, indices)\n",
    "        gene_test_index = np.intersect1d(test_index, indices)\n",
    "        \n",
    "        # Add the indices to the respective lists\n",
    "        train_indices.extend(gene_train_index)\n",
    "        test_indices.extend(gene_test_index)\n",
    "    \n",
    "    # Shuffle the indices\n",
    "    np.random.shuffle(train_indices)\n",
    "    np.random.shuffle(test_indices)\n",
    "    \n",
    "\n",
    "    # Append the train/test indices split to the list\n",
    "    train_test_splits.append((train_indices, test_indices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3f3d6bd3-4b88-4bf3-8624-afae18f0737b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159 40\n",
      "159 40\n",
      "159 40\n",
      "159 40\n",
      "160 39\n"
     ]
    }
   ],
   "source": [
    "for split in train_test_splits:\n",
    "    train = split[0]\n",
    "    test = split[1]\n",
    "    \n",
    "    print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53730466-75ea-4701-b2f6-811db7a34086",
   "metadata": {},
   "source": [
    "### Now, for each test/train index split up, I need to:\n",
    "\n",
    "### - Take 10% of the test data for validation\n",
    "### - Create x_train, g_train, and y_train\n",
    "### - Create x_val, g_val, and y_val\n",
    "### - Create x_test, g_test, and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8b2394d6-bd75-4fa5-b578-03eb2074db4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_wrapper(split, num_model):\n",
    "    \n",
    "    # Train and test\n",
    "    train_indices = split[0]\n",
    "    test_indices = split[1]\n",
    "    \n",
    "    # Take 10% of training data for validation and update training\n",
    "    num_validation_indices = int(0.1 * len(train_indices))  # I want 10% of the indices to be used for validation\n",
    "    validation_indices = np.random.choice(train_indices, size=num_validation_indices, replace=False)  # Randomly choose 10% of the indices for validation\n",
    "    train_indices = [index for index in train_indices if index not in validation_indices]  # Remove validation indices from train_indices\n",
    "    \n",
    "    #Prepare train\n",
    "    x_train, g_train, y_train = get_training(finetune_data, train_indices, num_model)\n",
    "    \n",
    "    #Prepare validation\n",
    "    x_validation, g_validation, y_validation = get_validation(finetune_data, validation_indices, num_model)\n",
    "    \n",
    "    #Prepare test\n",
    "    x_test, g_test, y_test = get_testing(finetune_data, test_indices, num_model)\n",
    "    \n",
    "    return (x_train, g_train, y_train, x_validation, g_validation, y_validation, x_test, g_test, y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5ff8e30d-c70f-4118-bdab-994d9adac485",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_training(dataset, train_indices, num_model):\n",
    "    \n",
    "    gene_path_train = 'data/genes/' + 'endogenous_train_' + str(num_model) + '.npy'\n",
    "    \n",
    "    train_dataset = finetune_data.loc[train_indices]\n",
    "    train_dataset = train_dataset.reset_index(drop = True)  #Need to reset indices so it doesn't throw an error\n",
    "\n",
    "\n",
    "    if not os.path.isfile(gene_path_train):\n",
    "        g_train = seq_concat(train_dataset)\n",
    "        np.save(gene_path_train, g_train)\n",
    "    else:\n",
    "        g_train = np.load(gene_path_train)\n",
    "\n",
    "\n",
    "    train_features, train_target = select_cols(train_dataset)  #Trained target features \n",
    "    train_type = train_dataset.loc[:, ['type_sub', 'type_ins', 'type_del']]\n",
    "\n",
    "    mean = pd.read_csv('data/mean.csv', header=None, index_col=0)\n",
    "    std = pd.read_csv('data/std.csv', header=None, index_col=0)\n",
    "\n",
    "    mean = mean.squeeze('columns')\n",
    "    std= std.squeeze('columns')\n",
    "\n",
    "    x_train = (train_features - mean) / std\n",
    "    y_train = train_target\n",
    "    y_train = pd.concat([y_train, train_type], axis=1)\n",
    "\n",
    "    g_train = torch.tensor(g_train, dtype=torch.float32, device=device)\n",
    "    x_train = torch.tensor(x_train.to_numpy(), dtype=torch.float32, device=device)\n",
    "    y_train = torch.tensor(y_train.to_numpy(), dtype=torch.float32, device=device)\n",
    "    \n",
    "    return([x_train, g_train, y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "779342d5-6c2f-4abb-ac8c-3362938f2344",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_validation(dataset, validation_indices, num_model):\n",
    "    \n",
    "    gene_path_validation = 'data/genes/' + 'endogenous_val_' + str(num_model) + '.npy'\n",
    "    \n",
    "    validation_dataset = finetune_data.loc[validation_indices]\n",
    "    validation_dataset = validation_dataset.reset_index(drop = True)  #Need to reset indices so it doesn't throw an error\n",
    "\n",
    "\n",
    "    if not os.path.isfile(gene_path_validation):\n",
    "        g_validation = seq_concat(validation_dataset)\n",
    "        np.save(gene_path_validation, g_validation)\n",
    "    else:\n",
    "        g_validation = np.load(gene_path_validation)\n",
    "\n",
    "\n",
    "    validation_features, validation_target = select_cols(validation_dataset)  \n",
    "    validation_type = validation_dataset.loc[:, ['type_sub', 'type_ins', 'type_del']]\n",
    "\n",
    "    mean = pd.read_csv('data/mean.csv', header=None, index_col=0)\n",
    "    std = pd.read_csv('data/std.csv', header=None, index_col=0)\n",
    "\n",
    "    mean = mean.squeeze('columns')\n",
    "    std= std.squeeze('columns')\n",
    "\n",
    "    x_validation = (validation_features - mean) / std\n",
    "    y_validation = validation_target\n",
    "    y_validation = pd.concat([y_validation, validation_type], axis=1)\n",
    "\n",
    "    g_validation = torch.tensor(g_validation, dtype=torch.float32, device=device)\n",
    "    x_validation = torch.tensor(x_validation.to_numpy(), dtype=torch.float32, device=device)\n",
    "    y_validation = torch.tensor(y_validation.to_numpy(), dtype=torch.float32, device=device)\n",
    "    \n",
    "    return([x_validation, g_validation, y_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "48b000f1-d335-407b-be88-f7a11db1ef2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_testing(dataset, test_indices, num_model):\n",
    "    \n",
    "\n",
    "    gene_path_test = 'data/genes/' + 'endogenous_test' +  str(num_model) +'.npy'\n",
    "    \n",
    "    test_dataset = finetune_data.loc[test_indices]\n",
    "    test_dataset = test_dataset.reset_index(drop = True)  #Need to reset indices so it doesn't throw an error\n",
    "\n",
    "    if not os.path.isfile(gene_path_test):\n",
    "        g_test = seq_concat(test_dataset)\n",
    "        np.save(gene_path_test, g_test)\n",
    "    else:\n",
    "        g_test = np.load(gene_path_test)\n",
    "\n",
    "    test_features, test_target = select_cols(test_dataset)  #Test target features \n",
    "    test_type = test_dataset.loc[:, ['type_sub', 'type_ins', 'type_del']]\n",
    "\n",
    "    mean = pd.read_csv('data/mean.csv', header=None, index_col=0)\n",
    "    std = pd.read_csv('data/std.csv', header=None, index_col=0)\n",
    "\n",
    "    mean = mean.squeeze('columns')\n",
    "    std= std.squeeze('columns')\n",
    "\n",
    "    x_test = (test_features - mean) / std\n",
    "    y_test = test_target\n",
    "    y_test = pd.concat([y_test, test_type], axis=1)\n",
    "\n",
    "    g_test = torch.tensor(g_test, dtype=torch.float32, device=device)\n",
    "    x_test = torch.tensor(x_test.to_numpy(), dtype=torch.float32, device=device)\n",
    "    y_test = torch.tensor(y_test.to_numpy(), dtype=torch.float32, device=device)\n",
    "    \n",
    "    return([x_test, g_test, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3059da-f751-4310-b42b-1738c2f89f08",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e8efe65a-daa5-4c33-83f4-d3cbaf526b88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "import time\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "873b32f2-683d-4736-b4bd-9094456d1bae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Optuna_Trainer:\n",
    "    \n",
    "    # Initializing attributes including training and testing sets g (one-hot encoding of input sequences), x (features), and y (Measured editing efficiencies).\n",
    "    def __init__(self, model, x_train, g_train, y_train, x_y_validation, g_y_validation, y_validation): \n",
    "        self.g_train = g_train   # Training data for g\n",
    "        self.x_train = x_train   # Training data for x \n",
    "        self.y_train = y_train   # Training data for y\n",
    "        self.g_val = g_validation       # Validation data for g\n",
    "        self.x_val = x_validation       # Validation data for x\n",
    "        self.y_val = y_validation       # Validation data for y\n",
    "        self.model = model       # Call machine learning model as an attribute of the object\n",
    "        self.lr = 1e-5           # Learning rate\n",
    "        self.wd = 1e-5           # Weight decay: Weight decay should typically be same value as the learning rate\n",
    "        self.bs = 8              # Batch size \n",
    "        self.ep = 100            # Number of epochs\n",
    "        \n",
    "        # Patience represents the number of consecutive trials where the validation loss does not decrease (performance is not improved).\n",
    "        self.patience = 20       # Changing patience value to 20. \n",
    "        self.delta = 1e-4        # Delta is the threshold needed for the difference between the previous minimum loss and the validation loss.\n",
    "\n",
    "    # Set up hyperparameter search space\n",
    "    def setup_trials(self, trial):\n",
    "        \n",
    "        #Parameters that need to be searched\n",
    "        self.lr = trial.suggest_categorical(\"lr\", [1e-4,1e-3,2e-3,5e-3, 1e-2])   # Categorical values for learning rate\n",
    "        self.wd = self.lr                                                        # Assign weight decay to be the same as the learning rate\n",
    "        self.bs = trial.suggest_categorical(\"batch_size\", [8, 16, 32])           # Categorical values for batch size\n",
    "        self.ep = trial.suggest_categorical(\"num_epochs\", [50, 100, 200, 500])   # Categorical values for number of epochs\n",
    "        \n",
    "        # Fixed parameters\n",
    "        self.hs = 128                    # Hidden size\n",
    "        self.nl = 1                      # Number of GRU layers\n",
    "        self.schedule = True             # Learning rate scheduler\n",
    "        \n",
    "        # Print trial hyperparameters\n",
    "        for key, value in trial.params.items():\n",
    "            print(\"{}: {}\".format(key, value))\n",
    "    \n",
    "    # Trains the DeepPrime model based on the provided testing and training data\n",
    "    def train_model(self, trial): \n",
    "        \n",
    "        min_loss = None                   #  Stores the minimum loss, initialize with no value\n",
    "        early_stopping_counter = 0        #  Track how many consecutive epochs have occurred without improvement in the validation loss, used to prevent overfitting.\n",
    "\n",
    "        #Trial object is created when Optuna generates a study object, so it's not something to explicitly point to\n",
    "        self.setup_trials(trial) # Sets up the trial with a set of hyperparameters derived from the setup_trials function\n",
    "\n",
    "\n",
    "        # Prepare the training data to run through the model\n",
    "        train_dataset = GeneFeatureDataset(self.g_train, self.x_train, self.y_train) \n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.bs, shuffle=True, drop_last=True) \n",
    "\n",
    "        # Prepare the testing and validation datasets\n",
    "        val_dataset = GeneFeatureDataset(self.g_val, self.x_val, self.y_val) \n",
    "        val_loader = DataLoader(val_dataset, batch_size=self.bs, shuffle=True) # Q: Shuffle?\n",
    "\n",
    "        optimizer = optim.AdamW(self.model.parameters(), lr=self.lr, weight_decay=self.wd)   # Sets up optimizer, I am also using AdamW\n",
    "        optimizer.zero_grad()  # Zeroes out gradients, kind of a \"hack\" where optimization is actually better when gradients are not stored\n",
    "        \n",
    "        criterion = BalancedMSELoss() # Loss function used in DeepPrime\n",
    "\n",
    "        # print(\"epoch\\ttrain_corr\\ttrain_loss\\ttrue_auc\\tpred_auc\\tval_corr\\tval_loss\\telapsed_time\")\n",
    "        for epoch in range(self.ep): # self.ep is the number of epochs, so here we are iterating through the epochs\n",
    "            \n",
    "            # Train\n",
    "            self.model.train()  # Sets model in training mode. Make sure to use self.model because model is now an attribute of the class itself.\n",
    "            \n",
    "            train_loss = []    # List that will keep track of the loss across the entire epoch\n",
    "            train_count = 0    # Number of samples processed in epoch\n",
    "    \n",
    "\n",
    "            # Works through each batch of data set up by the train_loader\n",
    "            for i, (g_batch, x_batch, y_batch) in enumerate(train_loader):\n",
    "                g_batch, x_batch, y_batch = g_batch.cuda(), x_batch.cuda(), y_batch.cuda() # We are on GPU, so move tensors to GPU\n",
    "\n",
    "                # Update values for all three tensors. Following permutations used in DeepPrime.\n",
    "                g_batch = g_batch.permute((0, 3, 1, 2))\n",
    "                x_batch = x_batch\n",
    "                y_batch = y_batch.reshape(-1, 4)\n",
    "\n",
    "\n",
    "                optimizer.zero_grad()  #Zero out gradient for each batch\n",
    "\n",
    "                output = self.model(g_batch, x_batch) # Send g and x through the model\n",
    "\n",
    "                total_loss = criterion(output, y_batch) # Calculate the loss between the model output and the actual measured efficiencies\n",
    "\n",
    "                total_loss.backward() # Computes gradients of the loss with repsect to the model parameters\n",
    "                optimizer.step()  # Applies optimization to update parameters\n",
    "\n",
    "                train_loss.append(x_batch.size(0) * total_loss.detach().cpu().numpy()) # Multiplies batch-loss by batch size to normalize for different sized batches during training\n",
    "                train_count += x_batch.size(0)  # Updates number of samples processed in the epoch\n",
    "\n",
    "            train_loss = sum(train_loss) / train_count  # train_loss now represents the average training loss across batches for the ENTIRE epoch\n",
    "\n",
    "\n",
    "            # Validation\n",
    "            self.model.eval()  # Set model in evaluation mode\n",
    "            \n",
    "            val_loss = []\n",
    "            val_count = 0\n",
    "\n",
    "            # Same as with training batches\n",
    "            for i, (g_batch, x_batch, y_batch) in enumerate(val_loader):\n",
    "                g_batch, x_batch, y_batch = g_batch.cuda(), x_batch.cuda(), y_batch.cuda()\n",
    "\n",
    "                g_batch = g_batch.permute((0, 3, 1, 2))\n",
    "                x_batch = x_batch\n",
    "                y_batch = y_batch.reshape(-1, 4)\n",
    "                \n",
    "                output = self.model(g_batch, x_batch)  #Run validation data through model\n",
    "\n",
    "                loss = criterion(output, y_batch)\n",
    "                \n",
    "                \n",
    "                val_loss.append(x_batch.size(0) * loss.detach().cpu().numpy())\n",
    "                val_count += x_batch.size(0)\n",
    "\n",
    "            val_loss = sum(val_loss) / val_count\n",
    "\n",
    "\n",
    "            # Summary of training progress\n",
    "            # print(\"{}\\t{:.4f}\\t{:.4f}\".format(epoch, train_loss, val_loss))\n",
    "\n",
    "            trial.report(val_loss, epoch) # Reports the result of the current epoch to Optuna, so Optuna can keep track of model performance throughout the trial.\n",
    "            \n",
    "\n",
    "            if min_loss is None:\n",
    "                min_loss = val_loss  \n",
    "            elif min_loss - val_loss > self.delta:                    # If the difference between the previous minimum loss and the current validation loss is greater than delta, update values\n",
    "                min_loss = val_loss                                   # Set the new minimum loss to current validation loss\n",
    "                early_stopping_counter = 0                            # Reset to 0, indicating no consecutive epochs with increasing validation loss.\n",
    "            elif min_loss - val_loss < self.delta:                    # No improvement in validation loss\n",
    "                early_stopping_counter += 1                           # Consecutive epoch for which there is no improvement on validation loss\n",
    "                if early_stopping_counter >= self.patience:           # At this point, further training is unlikely to improve/lower validation loss, so break\n",
    "                    break\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "        return val_loss # #Returns the loss across the epochs, as this is the value we want to minimize\n",
    "\n",
    "    def exec_study(self):\n",
    "        study = optuna.create_study()                      # Creates Optuna study object, maximizing correlation\n",
    "        study.optimize(self.train_model, n_trials=30)      # Runs train_model function n_trials times\n",
    "        return self.print_result(study)                    # Prints out hyperparameters used for combination that generated lowest validation loss.\n",
    "    \n",
    "    def print_result(self, study):\n",
    "        pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "        complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "        print(\"Study statistics:\")\n",
    "        print(\"Number of finished trials:\", len(study.trials))\n",
    "        print(\"Number of pruned trials:\", len(pruned_trials))\n",
    "        print(\"Number of complete trials:\", len(complete_trials))\n",
    "\n",
    "        print(\"Best trial:\")\n",
    "        best_trial = study.best_trial\n",
    "\n",
    "        print(\"Value: \", best_trial.value)\n",
    "\n",
    "        best_params = {}\n",
    "        print(\"Params:\")\n",
    "        for key, value in best_trial.params.items():\n",
    "            print(\"{}: {}\".format(key, value))\n",
    "            best_params[key] = value\n",
    "        for key, value in best_trial.user_attrs.items():\n",
    "            print(\"{}: {}\".format(key, value))\n",
    "            best_params[key] = value\n",
    "\n",
    "        return best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0513f736-297d-498e-aaa0-c4423c9f9b72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:18:39,349] A new study created in memory with name: no-name-2a607693-80a6-48f6-a61a-a9c5ceb153ae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model 0\n",
      "cuda:0\n",
      "lr: 0.0001\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:18:40,595] Trial 0 finished with value: 4.1349592208862305 and parameters: {'lr': 0.0001, 'batch_size': 16, 'num_epochs': 500}. Best is trial 0 with value: 4.1349592208862305.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:18:48,511] Trial 1 finished with value: 1.349531928698222 and parameters: {'lr': 0.0001, 'batch_size': 8, 'num_epochs': 200}. Best is trial 1 with value: 1.349531928698222.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:18:49,811] Trial 2 finished with value: 0.7784639596939087 and parameters: {'lr': 0.002, 'batch_size': 32, 'num_epochs': 500}. Best is trial 2 with value: 0.7784639596939087.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 16\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:18:51,297] Trial 3 finished with value: 0.8831098675727844 and parameters: {'lr': 0.002, 'batch_size': 16, 'num_epochs': 200}. Best is trial 2 with value: 0.7784639596939087.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:18:52,366] Trial 4 finished with value: 0.6742392182350159 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 200}. Best is trial 4 with value: 0.6742392182350159.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 16\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:18:53,855] Trial 5 finished with value: 0.6510604619979858 and parameters: {'lr': 0.005, 'batch_size': 16, 'num_epochs': 50}. Best is trial 5 with value: 0.6510604619979858.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:18:58,921] Trial 6 finished with value: 0.7581716616948445 and parameters: {'lr': 0.005, 'batch_size': 8, 'num_epochs': 200}. Best is trial 5 with value: 0.6510604619979858.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:19:03,237] Trial 7 finished with value: 0.6520135243733723 and parameters: {'lr': 0.0001, 'batch_size': 8, 'num_epochs': 100}. Best is trial 5 with value: 0.6510604619979858.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 8\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:19:06,463] Trial 8 finished with value: 0.7448562423388163 and parameters: {'lr': 0.001, 'batch_size': 8, 'num_epochs': 100}. Best is trial 5 with value: 0.6510604619979858.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 8\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:19:09,641] Trial 9 finished with value: 0.7865137259165446 and parameters: {'lr': 0.002, 'batch_size': 8, 'num_epochs': 500}. Best is trial 5 with value: 0.6510604619979858.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 16\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:19:11,389] Trial 10 finished with value: 0.8055393695831299 and parameters: {'lr': 0.005, 'batch_size': 16, 'num_epochs': 50}. Best is trial 5 with value: 0.6510604619979858.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 16\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:19:15,810] Trial 11 finished with value: 0.7168334126472473 and parameters: {'lr': 0.0001, 'batch_size': 16, 'num_epochs': 100}. Best is trial 5 with value: 0.6510604619979858.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 8\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:19:19,018] Trial 12 finished with value: 0.8903219064076742 and parameters: {'lr': 0.005, 'batch_size': 8, 'num_epochs': 50}. Best is trial 5 with value: 0.6510604619979858.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 16\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:19:21,706] Trial 13 finished with value: 0.7448946833610535 and parameters: {'lr': 0.01, 'batch_size': 16, 'num_epochs': 50}. Best is trial 5 with value: 0.6510604619979858.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:19:22,960] Trial 14 finished with value: 0.6374346017837524 and parameters: {'lr': 0.001, 'batch_size': 32, 'num_epochs': 100}. Best is trial 14 with value: 0.6374346017837524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 32\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:19:24,208] Trial 15 finished with value: 0.6608200073242188 and parameters: {'lr': 0.001, 'batch_size': 32, 'num_epochs': 50}. Best is trial 14 with value: 0.6374346017837524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:19:25,450] Trial 16 finished with value: 0.6755653619766235 and parameters: {'lr': 0.001, 'batch_size': 32, 'num_epochs': 100}. Best is trial 14 with value: 0.6374346017837524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:19:26,158] Trial 17 finished with value: 0.693601667881012 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 50}. Best is trial 14 with value: 0.6374346017837524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:19:27,341] Trial 18 finished with value: 0.7198883295059204 and parameters: {'lr': 0.001, 'batch_size': 32, 'num_epochs': 100}. Best is trial 14 with value: 0.6374346017837524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 16\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:19:29,082] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:19:29,791] Trial 20 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:19:34,025] Trial 21 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 16\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:19:37,887] Trial 22 finished with value: 0.7600034475326538 and parameters: {'lr': 0.0001, 'batch_size': 16, 'num_epochs': 100}. Best is trial 14 with value: 0.6374346017837524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 8\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:19:41,113] Trial 23 finished with value: 0.9899554093678792 and parameters: {'lr': 0.01, 'batch_size': 8, 'num_epochs': 100}. Best is trial 14 with value: 0.6374346017837524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 16\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:19:43,916] Trial 24 finished with value: 0.6670414209365845 and parameters: {'lr': 0.001, 'batch_size': 16, 'num_epochs': 100}. Best is trial 14 with value: 0.6374346017837524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 8\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:19:50,148] Trial 25 finished with value: 0.7348004062970479 and parameters: {'lr': 0.005, 'batch_size': 8, 'num_epochs': 100}. Best is trial 14 with value: 0.6374346017837524.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 32\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:19:51,594] Trial 26 finished with value: 0.6094299554824829 and parameters: {'lr': 0.0001, 'batch_size': 32, 'num_epochs': 50}. Best is trial 26 with value: 0.6094299554824829.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 32\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:19:52,501] Trial 27 finished with value: 0.5815373063087463 and parameters: {'lr': 0.0001, 'batch_size': 32, 'num_epochs': 50}. Best is trial 27 with value: 0.5815373063087463.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 32\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:19:53,467] Trial 28 finished with value: 0.5730008482933044 and parameters: {'lr': 0.0001, 'batch_size': 32, 'num_epochs': 50}. Best is trial 28 with value: 0.5730008482933044.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 32\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:19:54,378] Trial 29 finished with value: 0.5692780613899231 and parameters: {'lr': 0.0001, 'batch_size': 32, 'num_epochs': 50}. Best is trial 29 with value: 0.5692780613899231.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics:\n",
      "Number of finished trials: 30\n",
      "Number of pruned trials: 3\n",
      "Number of complete trials: 27\n",
      "Best trial:\n",
      "Value:  0.5692780613899231\n",
      "Params:\n",
      "lr: 0.0001\n",
      "batch_size: 32\n",
      "num_epochs: 50\n",
      "Model 0 complete.\n",
      "Training Model 1\n",
      "Start preprocessing the sequence done 2d\n",
      "(144,) 144 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:00<00:00, 2343.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(144,) 144 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:00<00:00, 1695.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(15,) 15 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 2271.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(15,) 15 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 1688.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(40,) 40 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 2283.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(40,) 40 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 1665.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:19:54,734] A new study created in memory with name: no-name-e1fe9c5a-213d-4f43-b587-01f4c54309b6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:20:09,471] Trial 0 finished with value: 0.7970897515614828 and parameters: {'lr': 0.0001, 'batch_size': 8, 'num_epochs': 200}. Best is trial 0 with value: 0.7970897515614828.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:20:10,280] Trial 1 finished with value: 0.329802542924881 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 500}. Best is trial 1 with value: 0.329802542924881.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:20:14,170] Trial 2 finished with value: 0.28826971848805744 and parameters: {'lr': 0.0001, 'batch_size': 8, 'num_epochs': 500}. Best is trial 2 with value: 0.28826971848805744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 16\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:20:18,009] Trial 3 finished with value: 0.20552277565002441 and parameters: {'lr': 0.002, 'batch_size': 16, 'num_epochs': 100}. Best is trial 3 with value: 0.20552277565002441.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 8\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:20:26,423] Trial 4 finished with value: 0.23683613340059917 and parameters: {'lr': 0.01, 'batch_size': 8, 'num_epochs': 100}. Best is trial 3 with value: 0.20552277565002441.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:20:27,215] Trial 5 finished with value: 0.1629093885421753 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 500}. Best is trial 5 with value: 0.1629093885421753.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 16\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:20:28,437] Trial 6 finished with value: 0.16101357340812683 and parameters: {'lr': 0.0001, 'batch_size': 16, 'num_epochs': 50}. Best is trial 6 with value: 0.16101357340812683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 16\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:20:29,783] Trial 7 finished with value: 0.4094410538673401 and parameters: {'lr': 0.01, 'batch_size': 16, 'num_epochs': 200}. Best is trial 6 with value: 0.16101357340812683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 32\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:20:31,202] Trial 8 finished with value: 0.18964917957782745 and parameters: {'lr': 0.0001, 'batch_size': 32, 'num_epochs': 50}. Best is trial 6 with value: 0.16101357340812683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 8\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:20:33,599] Trial 9 finished with value: 0.27737709681193035 and parameters: {'lr': 0.01, 'batch_size': 8, 'num_epochs': 50}. Best is trial 6 with value: 0.16101357340812683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 16\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:20:36,109] Trial 10 finished with value: 0.24865135550498962 and parameters: {'lr': 0.001, 'batch_size': 16, 'num_epochs': 50}. Best is trial 6 with value: 0.16101357340812683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:20:36,823] Trial 11 finished with value: 0.1779051423072815 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 500}. Best is trial 6 with value: 0.16101357340812683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:20:38,250] Trial 12 finished with value: 0.1652822196483612 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 50}. Best is trial 6 with value: 0.16101357340812683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:20:40,361] Trial 13 finished with value: 0.18049532175064087 and parameters: {'lr': 0.005, 'batch_size': 16, 'num_epochs': 500}. Best is trial 6 with value: 0.16101357340812683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 32\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:20:41,570] Trial 14 finished with value: 0.1667007952928543 and parameters: {'lr': 0.001, 'batch_size': 32, 'num_epochs': 50}. Best is trial 6 with value: 0.16101357340812683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:20:44,811] Trial 15 finished with value: 0.1782819777727127 and parameters: {'lr': 0.002, 'batch_size': 16, 'num_epochs': 500}. Best is trial 6 with value: 0.16101357340812683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 32\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:20:46,603] Trial 16 finished with value: 0.1742606908082962 and parameters: {'lr': 0.0001, 'batch_size': 32, 'num_epochs': 200}. Best is trial 6 with value: 0.16101357340812683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 16\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:20:48,749] Trial 17 finished with value: 0.18488802015781403 and parameters: {'lr': 0.005, 'batch_size': 16, 'num_epochs': 100}. Best is trial 6 with value: 0.16101357340812683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:20:50,124] Trial 18 finished with value: 0.1870318204164505 and parameters: {'lr': 0.005, 'batch_size': 16, 'num_epochs': 500}. Best is trial 6 with value: 0.16101357340812683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 32\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:20:50,762] Trial 19 finished with value: 0.19511643052101135 and parameters: {'lr': 0.0001, 'batch_size': 32, 'num_epochs': 50}. Best is trial 6 with value: 0.16101357340812683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:20:51,914] Trial 20 finished with value: 0.1716073602437973 and parameters: {'lr': 0.002, 'batch_size': 32, 'num_epochs': 500}. Best is trial 6 with value: 0.16101357340812683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:20:53,037] Trial 21 finished with value: 0.16290993988513947 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 50}. Best is trial 6 with value: 0.16101357340812683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:20:54,196] Trial 22 finished with value: 0.17837096750736237 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 50}. Best is trial 6 with value: 0.16101357340812683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:20:55,307] Trial 23 finished with value: 0.1636522263288498 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 50}. Best is trial 6 with value: 0.16101357340812683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:20:56,419] Trial 24 finished with value: 0.19715450704097748 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 50}. Best is trial 6 with value: 0.16101357340812683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 16\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:20:58,942] Trial 25 finished with value: 0.20451900362968445 and parameters: {'lr': 0.001, 'batch_size': 16, 'num_epochs': 50}. Best is trial 6 with value: 0.16101357340812683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 32\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:21:00,709] Trial 26 finished with value: 0.1931740790605545 and parameters: {'lr': 0.0001, 'batch_size': 32, 'num_epochs': 200}. Best is trial 6 with value: 0.16101357340812683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:21:01,848] Trial 27 finished with value: 0.17241480946540833 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 100}. Best is trial 6 with value: 0.16101357340812683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 16\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:21:03,320] Trial 28 finished with value: 0.21408851444721222 and parameters: {'lr': 0.005, 'batch_size': 16, 'num_epochs': 50}. Best is trial 6 with value: 0.16101357340812683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:21:05,769] Trial 29 finished with value: 0.21404676338036854 and parameters: {'lr': 0.0001, 'batch_size': 8, 'num_epochs': 200}. Best is trial 6 with value: 0.16101357340812683.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics:\n",
      "Number of finished trials: 30\n",
      "Number of pruned trials: 0\n",
      "Number of complete trials: 30\n",
      "Best trial:\n",
      "Value:  0.16101357340812683\n",
      "Params:\n",
      "lr: 0.0001\n",
      "batch_size: 16\n",
      "num_epochs: 50\n",
      "Model 1 complete.\n",
      "Training Model 2\n",
      "Start preprocessing the sequence done 2d\n",
      "(144,) 144 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:00<00:00, 2286.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(144,) 144 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:00<00:00, 1621.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(15,) 15 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 2252.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(15,) 15 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 1608.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(40,) 40 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 2195.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(40,) 40 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 1647.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:21:06,151] A new study created in memory with name: no-name-5b242ef9-4ac3-4937-b191-51c4a0874810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 8\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:21:11,875] Trial 0 finished with value: 0.13940040866533915 and parameters: {'lr': 0.001, 'batch_size': 8, 'num_epochs': 50}. Best is trial 0 with value: 0.13940040866533915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:21:12,917] Trial 1 finished with value: 0.15874174237251282 and parameters: {'lr': 0.001, 'batch_size': 32, 'num_epochs': 100}. Best is trial 0 with value: 0.13940040866533915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 8\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:21:18,787] Trial 2 finished with value: 0.20570078492164612 and parameters: {'lr': 0.002, 'batch_size': 8, 'num_epochs': 100}. Best is trial 0 with value: 0.13940040866533915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:21:20,874] Trial 3 finished with value: 0.13936717808246613 and parameters: {'lr': 0.0001, 'batch_size': 16, 'num_epochs': 500}. Best is trial 3 with value: 0.13936717808246613.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:21:22,138] Trial 4 finished with value: 0.16730935871601105 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 500}. Best is trial 3 with value: 0.13936717808246613.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:21:24,888] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 8\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:21:30,662] Trial 6 finished with value: 0.13539969424406686 and parameters: {'lr': 0.001, 'batch_size': 8, 'num_epochs': 500}. Best is trial 6 with value: 0.13539969424406686.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 8\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:21:36,501] Trial 7 finished with value: 0.1554642915725708 and parameters: {'lr': 0.002, 'batch_size': 8, 'num_epochs': 100}. Best is trial 6 with value: 0.13539969424406686.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 32\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:21:37,099] Trial 8 finished with value: 0.1631571650505066 and parameters: {'lr': 0.001, 'batch_size': 32, 'num_epochs': 200}. Best is trial 6 with value: 0.13539969424406686.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 8\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:21:42,756] Trial 9 finished with value: 0.1838231787085533 and parameters: {'lr': 0.001, 'batch_size': 8, 'num_epochs': 50}. Best is trial 6 with value: 0.13539969424406686.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:21:45,528] Trial 10 finished with value: 0.15955394506454468 and parameters: {'lr': 0.0001, 'batch_size': 16, 'num_epochs': 500}. Best is trial 6 with value: 0.13539969424406686.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:21:48,547] Trial 11 finished with value: 0.164797842502594 and parameters: {'lr': 0.0001, 'batch_size': 16, 'num_epochs': 500}. Best is trial 6 with value: 0.13539969424406686.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:21:51,276] Trial 12 finished with value: 0.1590779423713684 and parameters: {'lr': 0.0001, 'batch_size': 16, 'num_epochs': 500}. Best is trial 6 with value: 0.13539969424406686.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:21:53,553] Trial 13 finished with value: 0.21344751119613647 and parameters: {'lr': 0.01, 'batch_size': 16, 'num_epochs': 500}. Best is trial 6 with value: 0.13539969424406686.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:21:56,173] Trial 14 finished with value: 0.10888247191905975 and parameters: {'lr': 0.005, 'batch_size': 16, 'num_epochs': 500}. Best is trial 14 with value: 0.10888247191905975.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 8\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:01,090] Trial 15 finished with value: 0.21867230534553528 and parameters: {'lr': 0.005, 'batch_size': 8, 'num_epochs': 500}. Best is trial 14 with value: 0.10888247191905975.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:02,319] Trial 16 finished with value: 0.15168295800685883 and parameters: {'lr': 0.005, 'batch_size': 16, 'num_epochs': 500}. Best is trial 14 with value: 0.10888247191905975.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:08,257] Trial 17 finished with value: 0.14511077205340067 and parameters: {'lr': 0.005, 'batch_size': 8, 'num_epochs': 200}. Best is trial 14 with value: 0.10888247191905975.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 16\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:11,196] Trial 18 finished with value: 0.14466823637485504 and parameters: {'lr': 0.001, 'batch_size': 16, 'num_epochs': 50}. Best is trial 14 with value: 0.10888247191905975.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:13,071] Trial 19 finished with value: 0.11488346755504608 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 500}. Best is trial 14 with value: 0.10888247191905975.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:14,865] Trial 20 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:15,496] Trial 21 finished with value: 0.1409999132156372 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 500}. Best is trial 14 with value: 0.10888247191905975.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:16,834] Trial 22 finished with value: 0.1153726875782013 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 500}. Best is trial 14 with value: 0.10888247191905975.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:18,032] Trial 23 finished with value: 0.10842980444431305 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 500}. Best is trial 23 with value: 0.10842980444431305.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:18,659] Trial 24 finished with value: 0.14424817264080048 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 500}. Best is trial 23 with value: 0.10842980444431305.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:19,302] Trial 25 finished with value: 0.1344011425971985 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 500}. Best is trial 23 with value: 0.10842980444431305.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:19,942] Trial 26 finished with value: 0.12212434411048889 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 200}. Best is trial 23 with value: 0.10842980444431305.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:21,279] Trial 27 finished with value: 0.10143156349658966 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 50}. Best is trial 27 with value: 0.10143156349658966.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:22,079] Trial 28 finished with value: 0.1861487776041031 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 50}. Best is trial 27 with value: 0.10143156349658966.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 16\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:25,052] Trial 29 finished with value: 0.15026144683361053 and parameters: {'lr': 0.002, 'batch_size': 16, 'num_epochs': 50}. Best is trial 27 with value: 0.10143156349658966.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics:\n",
      "Number of finished trials: 30\n",
      "Number of pruned trials: 2\n",
      "Number of complete trials: 28\n",
      "Best trial:\n",
      "Value:  0.10143156349658966\n",
      "Params:\n",
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 50\n",
      "Model 2 complete.\n",
      "Training Model 3\n",
      "Start preprocessing the sequence done 2d\n",
      "(144,) 144 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:00<00:00, 2299.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(144,) 144 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:00<00:00, 1648.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(15,) 15 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 2281.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(15,) 15 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 1672.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(40,) 40 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 2264.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(40,) 40 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 1685.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:25,432] A new study created in memory with name: no-name-d8d26d20-5567-4974-8831-4177c46a1f40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:26,035] Trial 0 finished with value: 6.057900905609131 and parameters: {'lr': 0.0001, 'batch_size': 32, 'num_epochs': 100}. Best is trial 0 with value: 6.057900905609131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:28,088] Trial 1 finished with value: 0.21159598231315613 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 100}. Best is trial 1 with value: 0.21159598231315613.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:29,827] Trial 2 finished with value: 0.18046361207962036 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 500}. Best is trial 2 with value: 0.18046361207962036.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 32\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:30,458] Trial 3 finished with value: 0.19080200791358948 and parameters: {'lr': 0.0001, 'batch_size': 32, 'num_epochs': 200}. Best is trial 2 with value: 0.18046361207962036.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 16\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:31,809] Trial 4 finished with value: 0.19756731390953064 and parameters: {'lr': 0.0001, 'batch_size': 16, 'num_epochs': 100}. Best is trial 2 with value: 0.18046361207962036.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:34,475] Trial 5 finished with value: 0.20632033745447795 and parameters: {'lr': 0.001, 'batch_size': 8, 'num_epochs': 200}. Best is trial 2 with value: 0.18046361207962036.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 16\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:35,716] Trial 6 finished with value: 0.21652880311012268 and parameters: {'lr': 0.001, 'batch_size': 16, 'num_epochs': 100}. Best is trial 2 with value: 0.18046361207962036.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 16\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:39,565] Trial 7 finished with value: 0.1838708072900772 and parameters: {'lr': 0.005, 'batch_size': 16, 'num_epochs': 200}. Best is trial 2 with value: 0.18046361207962036.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 8\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:43,398] Trial 8 finished with value: 0.28874967694282533 and parameters: {'lr': 0.002, 'batch_size': 8, 'num_epochs': 500}. Best is trial 2 with value: 0.18046361207962036.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:44,067] Trial 9 finished with value: 0.19972838461399078 and parameters: {'lr': 0.002, 'batch_size': 32, 'num_epochs': 500}. Best is trial 2 with value: 0.18046361207962036.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:45,403] Trial 10 finished with value: 0.404865562915802 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 50}. Best is trial 2 with value: 0.18046361207962036.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:46,658] Trial 11 finished with value: 0.1803358793258667 and parameters: {'lr': 0.005, 'batch_size': 16, 'num_epochs': 500}. Best is trial 11 with value: 0.1803358793258667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:47,967] Trial 12 finished with value: 0.9543822407722473 and parameters: {'lr': 0.01, 'batch_size': 16, 'num_epochs': 500}. Best is trial 11 with value: 0.1803358793258667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:49,453] Trial 13 finished with value: 0.1503482460975647 and parameters: {'lr': 0.01, 'batch_size': 16, 'num_epochs': 500}. Best is trial 13 with value: 0.1503482460975647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:50,939] Trial 14 finished with value: 0.202781543135643 and parameters: {'lr': 0.005, 'batch_size': 16, 'num_epochs': 500}. Best is trial 13 with value: 0.1503482460975647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 16\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:53,360] Trial 15 finished with value: 0.190092071890831 and parameters: {'lr': 0.01, 'batch_size': 16, 'num_epochs': 50}. Best is trial 13 with value: 0.1503482460975647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:54,664] Trial 16 finished with value: 0.18381641805171967 and parameters: {'lr': 0.005, 'batch_size': 16, 'num_epochs': 500}. Best is trial 13 with value: 0.1503482460975647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 8\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:22:59,140] Trial 17 finished with value: 0.2112882951895396 and parameters: {'lr': 0.01, 'batch_size': 8, 'num_epochs': 500}. Best is trial 13 with value: 0.1503482460975647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:01,033] Trial 18 finished with value: 0.2183181196451187 and parameters: {'lr': 0.005, 'batch_size': 16, 'num_epochs': 500}. Best is trial 13 with value: 0.1503482460975647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 16\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:03,613] Trial 19 finished with value: 0.19520150125026703 and parameters: {'lr': 0.001, 'batch_size': 16, 'num_epochs': 50}. Best is trial 13 with value: 0.1503482460975647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:04,877] Trial 20 finished with value: 0.2510673403739929 and parameters: {'lr': 0.002, 'batch_size': 16, 'num_epochs': 500}. Best is trial 13 with value: 0.1503482460975647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:05,835] Trial 21 finished with value: 0.20287233591079712 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 500}. Best is trial 13 with value: 0.1503482460975647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:06,472] Trial 22 finished with value: 0.21713635325431824 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 500}. Best is trial 13 with value: 0.1503482460975647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 8\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:11,900] Trial 23 finished with value: 0.23629860083262125 and parameters: {'lr': 0.01, 'batch_size': 8, 'num_epochs': 500}. Best is trial 13 with value: 0.1503482460975647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:13,299] Trial 24 finished with value: 0.40155452489852905 and parameters: {'lr': 0.01, 'batch_size': 16, 'num_epochs': 500}. Best is trial 13 with value: 0.1503482460975647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:14,429] Trial 25 finished with value: 0.19754914939403534 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 500}. Best is trial 13 with value: 0.1503482460975647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:16,326] Trial 26 finished with value: 0.4071688950061798 and parameters: {'lr': 0.01, 'batch_size': 16, 'num_epochs': 500}. Best is trial 13 with value: 0.1503482460975647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 16\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:18,942] Trial 27 finished with value: 0.23173226416110992 and parameters: {'lr': 0.01, 'batch_size': 16, 'num_epochs': 50}. Best is trial 13 with value: 0.1503482460975647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:19,593] Trial 28 finished with value: 0.2192879170179367 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 200}. Best is trial 13 with value: 0.1503482460975647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:22,198] Trial 29 finished with value: 0.25465669929981233 and parameters: {'lr': 0.0001, 'batch_size': 8, 'num_epochs': 100}. Best is trial 13 with value: 0.1503482460975647.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics:\n",
      "Number of finished trials: 30\n",
      "Number of pruned trials: 0\n",
      "Number of complete trials: 30\n",
      "Best trial:\n",
      "Value:  0.1503482460975647\n",
      "Params:\n",
      "lr: 0.01\n",
      "batch_size: 16\n",
      "num_epochs: 500\n",
      "Model 3 complete.\n",
      "Training Model 4\n",
      "Start preprocessing the sequence done 2d\n",
      "(144,) 144 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:00<00:00, 2334.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(144,) 144 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:00<00:00, 1711.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(16,) 16 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 2271.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(16,) 16 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 1674.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(39,) 39 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 2331.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(39,) 39 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 1661.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:22,554] A new study created in memory with name: no-name-467e7359-bd91-4f60-80a5-1c8eaa3bc7b3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 32\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:23,150] Trial 0 finished with value: 4.157201766967773 and parameters: {'lr': 0.0001, 'batch_size': 32, 'num_epochs': 50}. Best is trial 0 with value: 4.157201766967773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:30,612] Trial 1 finished with value: 1.0839467644691467 and parameters: {'lr': 0.0001, 'batch_size': 8, 'num_epochs': 500}. Best is trial 1 with value: 1.0839467644691467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 8\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:36,305] Trial 2 finished with value: 0.147898830473423 and parameters: {'lr': 0.01, 'batch_size': 8, 'num_epochs': 50}. Best is trial 2 with value: 0.147898830473423.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 8\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:41,976] Trial 3 finished with value: 0.13544877618551254 and parameters: {'lr': 0.005, 'batch_size': 8, 'num_epochs': 500}. Best is trial 3 with value: 0.13544877618551254.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:44,803] Trial 4 finished with value: 0.12236564978957176 and parameters: {'lr': 0.0001, 'batch_size': 8, 'num_epochs': 200}. Best is trial 4 with value: 0.12236564978957176.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:45,659] Trial 5 finished with value: 0.11651873588562012 and parameters: {'lr': 0.0001, 'batch_size': 32, 'num_epochs': 100}. Best is trial 5 with value: 0.11651873588562012.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 16\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:47,111] Trial 6 finished with value: 0.12376357614994049 and parameters: {'lr': 0.0001, 'batch_size': 16, 'num_epochs': 50}. Best is trial 5 with value: 0.11651873588562012.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 16\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:48,387] Trial 7 finished with value: 0.15430903434753418 and parameters: {'lr': 0.001, 'batch_size': 16, 'num_epochs': 50}. Best is trial 5 with value: 0.11651873588562012.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 8\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:50,875] Trial 8 finished with value: 0.12146349623799324 and parameters: {'lr': 0.005, 'batch_size': 8, 'num_epochs': 500}. Best is trial 5 with value: 0.11651873588562012.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:51,524] Trial 9 finished with value: 0.2399459034204483 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 500}. Best is trial 5 with value: 0.11651873588562012.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:52,344] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:53,052] Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 8\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:56,197] Trial 12 finished with value: 0.13331548124551773 and parameters: {'lr': 0.005, 'batch_size': 8, 'num_epochs': 100}. Best is trial 5 with value: 0.11651873588562012.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 32\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:56,821] Trial 13 finished with value: 0.16539838910102844 and parameters: {'lr': 0.002, 'batch_size': 32, 'num_epochs': 200}. Best is trial 5 with value: 0.11651873588562012.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 16\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:23:58,318] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 8\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:24:02,457] Trial 15 finished with value: 0.2783767059445381 and parameters: {'lr': 0.005, 'batch_size': 8, 'num_epochs': 500}. Best is trial 5 with value: 0.11651873588562012.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:24:03,196] Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:24:06,866] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:24:08,414] Trial 18 finished with value: 0.2651669979095459 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 200}. Best is trial 5 with value: 0.11651873588562012.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:24:09,988] Trial 19 finished with value: 0.2249353528022766 and parameters: {'lr': 0.002, 'batch_size': 16, 'num_epochs': 500}. Best is trial 5 with value: 0.11651873588562012.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:24:11,207] Trial 20 finished with value: 0.22044311463832855 and parameters: {'lr': 0.001, 'batch_size': 32, 'num_epochs': 100}. Best is trial 5 with value: 0.11651873588562012.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:24:13,804] Trial 21 finished with value: 0.2493153065443039 and parameters: {'lr': 0.0001, 'batch_size': 8, 'num_epochs': 200}. Best is trial 5 with value: 0.11651873588562012.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:24:16,448] Trial 22 finished with value: 0.24720674008131027 and parameters: {'lr': 0.0001, 'batch_size': 8, 'num_epochs': 200}. Best is trial 5 with value: 0.11651873588562012.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:24:20,057] Trial 23 finished with value: 0.23172064870595932 and parameters: {'lr': 0.0001, 'batch_size': 8, 'num_epochs': 200}. Best is trial 5 with value: 0.11651873588562012.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:24:23,669] Trial 24 finished with value: 0.22720643877983093 and parameters: {'lr': 0.0001, 'batch_size': 8, 'num_epochs': 200}. Best is trial 5 with value: 0.11651873588562012.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:24:28,335] Trial 25 finished with value: 0.18879633396863937 and parameters: {'lr': 0.005, 'batch_size': 8, 'num_epochs': 200}. Best is trial 5 with value: 0.11651873588562012.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:24:32,358] Trial 26 finished with value: 0.143005833029747 and parameters: {'lr': 0.0001, 'batch_size': 8, 'num_epochs': 500}. Best is trial 5 with value: 0.11651873588562012.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:24:36,019] Trial 27 finished with value: 0.17577097564935684 and parameters: {'lr': 0.0001, 'batch_size': 8, 'num_epochs': 100}. Best is trial 5 with value: 0.11651873588562012.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:24:36,621] Trial 28 finished with value: 0.24711370468139648 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 100}. Best is trial 5 with value: 0.11651873588562012.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 16\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 11:24:37,850] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics:\n",
      "Number of finished trials: 30\n",
      "Number of pruned trials: 6\n",
      "Number of complete trials: 24\n",
      "Best trial:\n",
      "Value:  0.11651873588562012\n",
      "Params:\n",
      "lr: 0.0001\n",
      "batch_size: 32\n",
      "num_epochs: 100\n",
      "Model 4 complete.\n"
     ]
    }
   ],
   "source": [
    "# Run Optuna_Trainer\n",
    "\n",
    "n_models = 5\n",
    "\n",
    "for m in range(n_models):\n",
    "    print(f\"Training Model {m}\")\n",
    "    \n",
    "    #Get the necessary information\n",
    "    split = train_test_splits[m]   #There are the same number of splits as there are models\n",
    "    x_train, g_train, y_train, x_validation, g_validation, y_validation, x_test, g_test, y_test = get_wrapper(split, m)\n",
    "    \n",
    "    \n",
    "    # Set random seed\n",
    "    random_seed = m\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    print(device)\n",
    "\n",
    "    # Load pre-trained model\n",
    "    model = GeneInteractionModel(hidden_size=128, num_layers=1).to(device)  # Model\n",
    "    model.load_state_dict(torch.load('models/ontarget/final/model_{}.pt'.format(m % 5)))  # Loads weights, biases from this pre-trained model\n",
    "\n",
    "    # Create a Trainer instance for each model\n",
    "    trainer = Optuna_Trainer(model, x_train, g_train, y_train, x_validation, g_validation, y_validation)\n",
    "\n",
    "    # Execute hyperparameter study\n",
    "    trainer.exec_study()\n",
    "\n",
    "    print(f\"Model {m} complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8fab60-d9d1-4e3a-8801-10f0473362b0",
   "metadata": {},
   "source": [
    "# Fine-tuning with best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b260ff6c-e267-4972-85fc-f8d4aeead8d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \n",
    "    def __init__(self, model, x_train, g_train, y_train, x_validation, g_validation, y_validation): \n",
    "        self.g_train = g_train\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.g_val = g_validation\n",
    "        self.x_val = x_validation\n",
    "        self.y_val = y_validation\n",
    "        self.model = model\n",
    "\n",
    "        self.patience = 20\n",
    "        self.delta = 1e-4\n",
    "        \n",
    "        if m == 0:\n",
    "            self.lr = 0.0001\n",
    "            self.bs = 32\n",
    "            self.ep = 50\n",
    "            \n",
    "        elif m == 1:\n",
    "            self.lr = 0.0001\n",
    "            self.bs = 16\n",
    "            self.ep = 50    \n",
    "            \n",
    "        elif m == 2:\n",
    "            self.lr = 0.005\n",
    "            self.bs = 32\n",
    "            self.ep = 50    \n",
    "            \n",
    "        elif m == 3:\n",
    "            self.lr = 0.01\n",
    "            self.bs = 16\n",
    "            self.ep = 500\n",
    "          \n",
    "        elif m == 4:\n",
    "            self.lr = 0.0001\n",
    "            self.bs = 32\n",
    "            self.ep = 100     \n",
    "            \n",
    "\n",
    "        self.wd = self.lr\n",
    "    \n",
    "        print(m, self.lr, self.bs, self.ep)\n",
    "\n",
    "    def train_model(self):                # Does not take in trial as a parameter because we are no longer testing out different hyperparameters.\n",
    "        \n",
    "        min_loss = None                   # Stores the minimum loss\n",
    "        early_stopping_counter = 0        # Track how many consecutive epochs have occurred without improvement in the validation loss, used to prevent overfitting.\n",
    "        \n",
    "        \n",
    "        train_dataset = GeneFeatureDataset(self.g_train, self.x_train, self.y_train) \n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.bs, shuffle=True, drop_last=True) \n",
    "\n",
    "\n",
    "        val_dataset = GeneFeatureDataset(self.g_val, self.x_val, self.y_val) \n",
    "        val_loader = DataLoader(val_dataset, batch_size=self.bs, shuffle=True)\n",
    "\n",
    "        optimizer = optim.AdamW(self.model.parameters(), lr=self.lr, weight_decay=self.wd) \n",
    "        optimizer.zero_grad()  #Q: Zeroes out gradients?\n",
    "        \n",
    "\n",
    "        criterion = BalancedMSELoss()\n",
    "\n",
    "        print(\"epoch\\ttrain_loss\\tval_loss\")\n",
    "        for epoch in range(self.ep): # self.ep is the number of epochs, so here we are iterating through the epochs\n",
    "            \n",
    "            # Train\n",
    "            self.model.train()  # Sets model in training mode\n",
    "            train_loss = []\n",
    "            train_count = 0\n",
    "    \n",
    "\n",
    "            # Works through each batch of data set up by the train_loader\n",
    "            for i, (g_batch, x_batch, y_batch) in enumerate(train_loader):\n",
    "                g_batch, x_batch, y_batch = g_batch.cuda(), x_batch.cuda(), y_batch.cuda() # If gpu is available, moves tensors to GPU\n",
    "                \n",
    "                g_batch = g_batch.permute((0, 3, 1, 2))\n",
    "                x_batch = x_batch\n",
    "                y_batch = y_batch.reshape(-1, 4)\n",
    "\n",
    "                optimizer.zero_grad()  # Q: Why should I zero the gradient again?\n",
    "\n",
    "                output = self.model(g_batch, x_batch) # Send g and x through the model\n",
    "\n",
    "                total_loss = criterion(output, y_batch) # Calculate the loss between the model output and the measured efficiencies\n",
    "\n",
    "                total_loss.backward()\n",
    "                optimizer.step()  # Applies optimization to update parameters\n",
    "\n",
    "                train_loss.append(x_batch.size(0) * total_loss.detach().cpu().numpy())\n",
    "                train_count += x_batch.size(0)\n",
    "                \n",
    "\n",
    "            train_loss = sum(train_loss) / train_count\n",
    "\n",
    "\n",
    "            # Validation\n",
    "            \n",
    "            self.model.eval()  # Set model in evaluation mode\n",
    "            \n",
    "            val_loss = []\n",
    "            val_count = 0\n",
    "\n",
    "            # Same as with training batches\n",
    "            for i, (g_batch, x_batch, y_batch) in enumerate(val_loader):\n",
    "                g_batch, x_batch, y_batch = g_batch.cuda(), x_batch.cuda(), y_batch.cuda()\n",
    "\n",
    "                g_batch = g_batch.permute((0, 3, 1, 2))\n",
    "                x_batch = x_batch\n",
    "                y_batch = y_batch.reshape(-1, 4)\n",
    "                \n",
    "                output = self.model(g_batch, x_batch)  #Run validation data through model\n",
    "\n",
    "                loss = criterion(output, y_batch)\n",
    "                \n",
    "                val_loss.append(x_batch.size(0) * loss.detach().cpu().numpy())\n",
    "                val_count += x_batch.size(0)\n",
    "\n",
    "            val_loss = sum(val_loss) / val_count\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "            # Summary of training progress\n",
    "            # print(\"{}\\t{:.4f}\\t{:.4f}\".format(epoch, train_loss, val_loss))\n",
    "\n",
    "            \n",
    "\n",
    "            if min_loss is None:\n",
    "                min_loss = val_loss  \n",
    "            elif min_loss - val_loss > self.delta:                    # If the difference between the previous minimum loss and the current validation loss is greater than delta, update values\n",
    "                min_loss = val_loss                                   # Set the new minimum loss to current validation loss\n",
    "                early_stopping_counter = 0                            # Reset to 0, indicating no consecutive epochs with increasing validation loss.\n",
    "            elif min_loss - val_loss < self.delta:                    # No improvement in validation loss\n",
    "                early_stopping_counter += 1                           # Consecutive epoch for which there is no improvement on validation loss\n",
    "                if early_stopping_counter >= self.patience:           # At this point, further training is unlikely to improve/lower validation loss, so break\n",
    "                    break\n",
    "\n",
    "        print(val_loss)\n",
    "        return val_loss  # Returns the minimum validation loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0a1a7edd-4b4a-4679-b5aa-cbeb46c1c325",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model 0\n",
      "cuda:0\n",
      "0 0.0001 32 50\n",
      "epoch\ttrain_loss\tval_loss\n",
      "6.045087814331055\n",
      "Model 0 complete.\n",
      "Training Model 1\n",
      "cuda:0\n",
      "1 0.0001 16 50\n",
      "epoch\ttrain_loss\tval_loss\n",
      "7.048244476318359\n",
      "Model 1 complete.\n",
      "Training Model 2\n",
      "cuda:0\n",
      "2 0.005 32 50\n",
      "epoch\ttrain_loss\tval_loss\n",
      "0.2911105453968048\n",
      "Model 2 complete.\n",
      "Training Model 3\n",
      "cuda:0\n",
      "3 0.01 16 500\n",
      "epoch\ttrain_loss\tval_loss\n",
      "0.7638047933578491\n",
      "Model 3 complete.\n",
      "Training Model 4\n",
      "cuda:0\n",
      "4 0.0001 32 100\n",
      "epoch\ttrain_loss\tval_loss\n",
      "4.157756805419922\n",
      "Model 4 complete.\n"
     ]
    }
   ],
   "source": [
    "# Run Trainer\n",
    "\n",
    "n_models = 5\n",
    "\n",
    "for m in range(n_models):\n",
    "    print(f\"Training Model {m}\")\n",
    "    \n",
    "    x_train, g_train, y_train, x_validation, g_validation, y_validation, x_test, g_test, y_test = get_wrapper(split, m)\n",
    "    \n",
    "    # Set random seed\n",
    "    random_seed = m\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    print(device)\n",
    "\n",
    "    # Load pre-trained model\n",
    "    model = GeneInteractionModel(hidden_size=128, num_layers=1).to(device)  # Model\n",
    "    model.load_state_dict(torch.load('models/ontarget/final/model_{}.pt'.format(m % 5)))  # Loads weights, biases from this pre-trained model\n",
    "\n",
    "    # Create a Trainer instance for each model\n",
    "    trainer = Trainer(model, x_train, g_train, y_train, x_validation, g_validation, y_validation)\n",
    "\n",
    "    # Execute hyperparameter study\n",
    "    trainer.train_model()\n",
    "    \n",
    "    torch.save(model.state_dict(), f'models/endogenous/model_{m}.pt')   # Model has now been updated after training, so store the model in a new folder\n",
    "\n",
    "    print(f\"Model {m} complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb1ebff-e240-49ee-8f98-1fad744ad318",
   "metadata": {},
   "source": [
    "### Now, run test sets through their respective models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "b491800a-06d8-4bad-a632-6d5125b04b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_deepprime_score(df_input, num_model, pe_system='PE2', cell_type='HEK293T'):\n",
    "    \n",
    "\n",
    "    mean = pd.read_csv('../DeepPrime-main/models/DeepPrime/DeepPrime_base/mean.csv', header=None, index_col=0)\n",
    "    std  = pd.read_csv('../DeepPrime-main/models/DeepPrime/DeepPrime_base/std.csv', header=None, index_col=0)\n",
    "\n",
    "    mean = mean.squeeze('columns')\n",
    "    std = std.squeeze('columns')\n",
    "\n",
    "    test_features, test_target = select_cols(test) \n",
    "\n",
    "    g_test = seq_concat(test)\n",
    "    x_test = (test_features - mean) / std\n",
    "\n",
    "    g_test = torch.tensor(g_test, dtype=torch.float32, device=device)\n",
    "    x_test = torch.tensor(x_test.to_numpy(), dtype=torch.float32, device=device)\n",
    "\n",
    "    preds  = []\n",
    "\n",
    "    # Model particular to the test dataset\n",
    "    model = GeneInteractionModel(hidden_size=128, num_layers=1).to(device)\n",
    "    model.load_state_dict(torch.load('models/endogenous/model_{}.pt'.format(0)))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        g, x = g_test, x_test\n",
    "        g = g.permute((0, 3, 1, 2))\n",
    "        pred = model(g, x).detach().cpu().numpy()\n",
    "    preds.append(pred)\n",
    "\n",
    "    # Need this line!!\n",
    "    preds = np.squeeze(np.array(preds))\n",
    "    # preds = np.exp(preds) - 1 # Really am not sure whether I need this line or not, so check with and without, probably\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "30f35dbf-2f09-4f0b-91b2-7c80aec36147",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preprocessing the sequence done 2d\n",
      "(40,) 40 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 1906.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(40,) 40 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 1259.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(40,) 40 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 1662.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(40,) 40 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 1256.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(40,) 40 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 2196.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(40,) 40 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 1612.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(40,) 40 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 2205.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(40,) 40 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 1621.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(39,) 39 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 2197.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(39,) 39 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 1580.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n"
     ]
    }
   ],
   "source": [
    "all_test_df = []\n",
    "\n",
    "for i in range(len(train_test_splits)):\n",
    "    \n",
    "    test_indices = train_test_splits[i][1] # This extracts out the test indices \n",
    "    \n",
    "    test = finetune_data.loc[test_indices] # Subset entire data just for the test indices used for this particular model\n",
    "    test = test.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    test['DeepPrime_score'] = calculate_deepprime_score(test, num_model = i)\n",
    "    \n",
    "    all_test_df.append(test)\n",
    "    test.to_csv('Test_' + str(i) + '.csv')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "29d8e87b-0bd2-414b-bd96-f0036e5c139c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene</th>\n",
       "      <th>ID</th>\n",
       "      <th>WT74_On</th>\n",
       "      <th>Edited74_On</th>\n",
       "      <th>PBSlen</th>\n",
       "      <th>RTlen</th>\n",
       "      <th>RT-PBSlen</th>\n",
       "      <th>Edit_pos</th>\n",
       "      <th>Edit_len</th>\n",
       "      <th>RHA_len</th>\n",
       "      <th>...</th>\n",
       "      <th>nGCcnt2</th>\n",
       "      <th>nGCcnt3</th>\n",
       "      <th>fGCcont1</th>\n",
       "      <th>fGCcont2</th>\n",
       "      <th>fGCcont3</th>\n",
       "      <th>MFE3</th>\n",
       "      <th>MFE4</th>\n",
       "      <th>DeepSpCas9_score</th>\n",
       "      <th>Measured_PE_efficiency</th>\n",
       "      <th>DeepPrime_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RUNX1</td>\n",
       "      <td>EDFIG5C_RUNX1_10NT</td>\n",
       "      <td>GGGTGCATTTTCAGGAGGAAGCGATGGCTTCAGACAGCATATTTGA...</td>\n",
       "      <td>xxxxxxATTTTCAGGAGGAAGCGATTGCTTCAxxxxxxxxxxxxxx...</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>45.454545</td>\n",
       "      <td>42.307692</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>57.854034</td>\n",
       "      <td>13.548111</td>\n",
       "      <td>0.236303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RNF2</td>\n",
       "      <td>FIG2A_PE2_RNF2_10</td>\n",
       "      <td>GGCAGTCATCTTAGTCATTACCTGAGGTGTTCGTTGTAACTCATAT...</td>\n",
       "      <td>xxxxxxCATCTTAGTCATTACATGAGGTGTTxxxxxxxxxxxxxxx...</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.229725</td>\n",
       "      <td>6.623650</td>\n",
       "      <td>0.006820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HEK3</td>\n",
       "      <td>EDFIG6D_HEK3_PE2_A8</td>\n",
       "      <td>TTGGGGCCCAGACTGAGCACGTGATGGCAGAGGAAAGGAAGCCCTG...</td>\n",
       "      <td>xxxxxxxxCAGACTGAGCACGCGATGGCAGAxxxxxxxxxxxxxxx...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.869565</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>63.264858</td>\n",
       "      <td>16.010170</td>\n",
       "      <td>1.503004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EMX1</td>\n",
       "      <td>FIG2B_EMX1_10</td>\n",
       "      <td>GCCTGAGTCCGAGCAGAAGAAGAAGGGCTCCCATCACATCAACCGG...</td>\n",
       "      <td>xxxxxxxxCCGAGCAGAAGAACAAGGGCTCCCATxxxxxxxxxxxx...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>53.846154</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>57.692308</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.540627</td>\n",
       "      <td>17.159046</td>\n",
       "      <td>0.189190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DNMT1</td>\n",
       "      <td>EDFIG5B_DNMT1_10NT</td>\n",
       "      <td>TGGGGATTCCTGGTGCCAGAAACAGGGGTGACGGGAGGGCAGAACT...</td>\n",
       "      <td>xxxxxxxxCCTGGTGCCAGAAACAGTGGTGACGGGAGGGCAGxxxx...</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>64.705882</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>65.144363</td>\n",
       "      <td>4.924110</td>\n",
       "      <td>0.813578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>VEGFA</td>\n",
       "      <td>EDFIG5A_VEGFA_10NT</td>\n",
       "      <td>CTTTGATGTCTGCAGGCCAGATGAGGGCTCCAGATGGCACATTGTC...</td>\n",
       "      <td>xxxxxxxxTCTGCAGGCCAGATGAGTGCTCCAGATGGCACATTxxx...</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>54.285714</td>\n",
       "      <td>-8.7</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>66.789276</td>\n",
       "      <td>29.943587</td>\n",
       "      <td>0.751485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>VEGFA</td>\n",
       "      <td>EDFIG5A_VEGFA_10NT</td>\n",
       "      <td>CTTTGATGTCTGCAGGCCAGATGAGGGCTCCAGATGGCACATTGTC...</td>\n",
       "      <td>xxxxxxxxTCTGCAGGCCAGATGAGTGCTCCAGATGxxxxxxxxxx...</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>57.142857</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>66.789276</td>\n",
       "      <td>17.794598</td>\n",
       "      <td>0.271042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>FANCF</td>\n",
       "      <td>FIG2A_PE2_FANCF_10</td>\n",
       "      <td>TCATGGAATCCCTTCTGCAGCACCTGGATCGCTTTTCCGAGCTTCT...</td>\n",
       "      <td>xxxxxxxATCCCTTCTGCAGCACCTTGATCGCTTTTCCxxxxxxxx...</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>57.142857</td>\n",
       "      <td>47.058824</td>\n",
       "      <td>51.612903</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>60.384285</td>\n",
       "      <td>12.988252</td>\n",
       "      <td>1.613805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>HEK3</td>\n",
       "      <td>FIG2A_PE2_HEK3_10</td>\n",
       "      <td>TTGGGGCCCAGACTGAGCACGTGATGGCAGAGGAAAGGAAGCCCTG...</td>\n",
       "      <td>xxxxxxxxCAGACTGAGCACGAGATGGCAGAxxxxxxxxxxxxxxx...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>56.521739</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>63.264858</td>\n",
       "      <td>14.645327</td>\n",
       "      <td>1.248609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>HEK4</td>\n",
       "      <td>FIG2A_PE2_HEK4_10</td>\n",
       "      <td>CGGTGGCACTGCGGCTGGAGGTGGGGGTTAAAGCGGAGACTCTGGT...</td>\n",
       "      <td>xxxxxxxACTGCGGCTGGAGGTTGGGGTTAAAGCxxxxxxxxxxxx...</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>71.428571</td>\n",
       "      <td>46.153846</td>\n",
       "      <td>59.259259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>54.310997</td>\n",
       "      <td>1.758639</td>\n",
       "      <td>0.163209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gene                   ID  \\\n",
       "0   RUNX1   EDFIG5C_RUNX1_10NT   \n",
       "1    RNF2    FIG2A_PE2_RNF2_10   \n",
       "2    HEK3  EDFIG6D_HEK3_PE2_A8   \n",
       "3    EMX1        FIG2B_EMX1_10   \n",
       "4   DNMT1   EDFIG5B_DNMT1_10NT   \n",
       "..    ...                  ...   \n",
       "34  VEGFA   EDFIG5A_VEGFA_10NT   \n",
       "35  VEGFA   EDFIG5A_VEGFA_10NT   \n",
       "36  FANCF   FIG2A_PE2_FANCF_10   \n",
       "37   HEK3    FIG2A_PE2_HEK3_10   \n",
       "38   HEK4    FIG2A_PE2_HEK4_10   \n",
       "\n",
       "                                              WT74_On  \\\n",
       "0   GGGTGCATTTTCAGGAGGAAGCGATGGCTTCAGACAGCATATTTGA...   \n",
       "1   GGCAGTCATCTTAGTCATTACCTGAGGTGTTCGTTGTAACTCATAT...   \n",
       "2   TTGGGGCCCAGACTGAGCACGTGATGGCAGAGGAAAGGAAGCCCTG...   \n",
       "3   GCCTGAGTCCGAGCAGAAGAAGAAGGGCTCCCATCACATCAACCGG...   \n",
       "4   TGGGGATTCCTGGTGCCAGAAACAGGGGTGACGGGAGGGCAGAACT...   \n",
       "..                                                ...   \n",
       "34  CTTTGATGTCTGCAGGCCAGATGAGGGCTCCAGATGGCACATTGTC...   \n",
       "35  CTTTGATGTCTGCAGGCCAGATGAGGGCTCCAGATGGCACATTGTC...   \n",
       "36  TCATGGAATCCCTTCTGCAGCACCTGGATCGCTTTTCCGAGCTTCT...   \n",
       "37  TTGGGGCCCAGACTGAGCACGTGATGGCAGAGGAAAGGAAGCCCTG...   \n",
       "38  CGGTGGCACTGCGGCTGGAGGTGGGGGTTAAAGCGGAGACTCTGGT...   \n",
       "\n",
       "                                          Edited74_On  PBSlen  RTlen  \\\n",
       "0   xxxxxxATTTTCAGGAGGAAGCGATTGCTTCAxxxxxxxxxxxxxx...      15     11   \n",
       "1   xxxxxxCATCTTAGTCATTACATGAGGTGTTxxxxxxxxxxxxxxx...      15     10   \n",
       "2   xxxxxxxxCAGACTGAGCACGCGATGGCAGAxxxxxxxxxxxxxxx...      13     10   \n",
       "3   xxxxxxxxCCGAGCAGAAGAACAAGGGCTCCCATxxxxxxxxxxxx...      13     13   \n",
       "4   xxxxxxxxCCTGGTGCCAGAAACAGTGGTGACGGGAGGGCAGxxxx...      13     21   \n",
       "..                                                ...     ...    ...   \n",
       "34  xxxxxxxxTCTGCAGGCCAGATGAGTGCTCCAGATGGCACATTxxx...      13     22   \n",
       "35  xxxxxxxxTCTGCAGGCCAGATGAGTGCTCCAGATGxxxxxxxxxx...      13     15   \n",
       "36  xxxxxxxATCCCTTCTGCAGCACCTTGATCGCTTTTCCxxxxxxxx...      14     17   \n",
       "37  xxxxxxxxCAGACTGAGCACGAGATGGCAGAxxxxxxxxxxxxxxx...      13     10   \n",
       "38  xxxxxxxACTGCGGCTGGAGGTTGGGGTTAAAGCxxxxxxxxxxxx...      14     13   \n",
       "\n",
       "    RT-PBSlen  Edit_pos  Edit_len  RHA_len  ...  nGCcnt2  nGCcnt3   fGCcont1  \\\n",
       "0          26         5         1        6  ...        5       11  40.000000   \n",
       "1          25         1         1        9  ...        4        9  33.333333   \n",
       "2          23         1         1        9  ...        6       14  61.538462   \n",
       "3          26         1         1       12  ...        8       15  53.846154   \n",
       "4          34         5         1       16  ...       14       22  61.538462   \n",
       "..        ...       ...       ...      ...  ...      ...      ...        ...   \n",
       "34         35         5         1       17  ...       11       19  61.538462   \n",
       "35         28         5         1       10  ...        8       16  61.538462   \n",
       "36         31         5         1       12  ...        8       16  57.142857   \n",
       "37         23         1         1        9  ...        5       13  61.538462   \n",
       "38         27         2         1       11  ...        6       16  71.428571   \n",
       "\n",
       "     fGCcont2   fGCcont3  MFE3  MFE4  DeepSpCas9_score  \\\n",
       "0   45.454545  42.307692  -5.5  -1.4         57.854034   \n",
       "1   40.000000  36.000000  -0.2   0.0         52.229725   \n",
       "2   60.000000  60.869565  -0.6  -0.7         63.264858   \n",
       "3   61.538462  57.692308  -4.4   0.0         69.540627   \n",
       "4   66.666667  64.705882  -3.5  -1.6         65.144363   \n",
       "..        ...        ...   ...   ...               ...   \n",
       "34  50.000000  54.285714  -8.7  -3.3         66.789276   \n",
       "35  53.333333  57.142857  -8.2  -3.3         66.789276   \n",
       "36  47.058824  51.612903  -2.5  -0.4         60.384285   \n",
       "37  50.000000  56.521739  -0.2  -0.7         63.264858   \n",
       "38  46.153846  59.259259   0.0  -3.5         54.310997   \n",
       "\n",
       "    Measured_PE_efficiency  DeepPrime_score  \n",
       "0                13.548111         0.236303  \n",
       "1                 6.623650         0.006820  \n",
       "2                16.010170         1.503004  \n",
       "3                17.159046         0.189190  \n",
       "4                 4.924110         0.813578  \n",
       "..                     ...              ...  \n",
       "34               29.943587         0.751485  \n",
       "35               17.794598         0.271042  \n",
       "36               12.988252         1.613805  \n",
       "37               14.645327         1.248609  \n",
       "38                1.758639         0.163209  \n",
       "\n",
       "[199 rows x 30 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate all the test data frames\n",
    "\n",
    "concatenated = pd.concat(all_test_df)\n",
    "concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "62e258c6-2a3b-4ccb-8da5-670e0cbf9786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "4eab0d3e-90fa-4727-b013-27b690f5cf9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2826689703501266 0.41654338565623017\n"
     ]
    }
   ],
   "source": [
    "x = concatenated['Measured_PE_efficiency']\n",
    "y = concatenated['DeepPrime_score']\n",
    "                           \n",
    "pearson_corr, pearson_p_value = pearsonr(x, y)\n",
    "spearman_corr, spearman_p_value = spearmanr(x, y)\n",
    "                           \n",
    "\n",
    "print(pearson_corr, spearman_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c6827784-00d9-4ede-9565-c4aae672be60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, y, s= 0.5, alpha=0.5)\n",
    "\n",
    "# for gene, color in color_mapping.items():\n",
    "#     plt.scatter(x[df_input['Gene'] == gene], y[df_input['Gene'] == gene], \n",
    "#                 s=10, c=color, label=gene)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Measured_Editing_Frequency')\n",
    "plt.ylabel('DeepPrime_Predicted_Efficiency')\n",
    "plt.title('ClinVar_Test Data: Endogenous Measured vs. Predicted Efficiencies')\n",
    "# plt.legend(title='Gene', loc = 'lower right')\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), color='red', label='Regression Line (Pearson)')\n",
    "\n",
    "\n",
    "plt.text(min(x), max(y), f\"r: {pearson_corr:.2f}\", fontsize=10)\n",
    "\n",
    "# Annotate Spearman correlation coefficient\n",
    "plt.text(min(x), max(y)-2, f\"R: {spearman_corr:.2f}\", fontsize=10)\n",
    "\n",
    "plt.text(min(x), max(y)-4, \"n = \"+ str(len(concatenated)), fontsize=10)\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepPrime",
   "language": "python",
   "name": "genet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
