{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "037ba7d5-e9c1-490f-8f7c-6c7338e6d5ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.optim import AdamW, lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from utils.data import GeneFeatureDataset, seq_concat, select_cols\n",
    "from utils.model import GeneInteractionModel\n",
    "from utils.loss import BalancedMSELoss\n",
    "\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from itertools import combinations\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a4e862cf-732e-4e84-94f3-cab49b0aae9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f258800-b651-4bd5-a839-96788ee034ad",
   "metadata": {},
   "source": [
    "# Create test/train splits for 5 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0ac3127b-8768-43da-b963-8a135dfcda38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene</th>\n",
       "      <th>ID</th>\n",
       "      <th>WT74_On</th>\n",
       "      <th>Edited74_On</th>\n",
       "      <th>PBSlen</th>\n",
       "      <th>RTlen</th>\n",
       "      <th>RT-PBSlen</th>\n",
       "      <th>Edit_pos</th>\n",
       "      <th>Edit_len</th>\n",
       "      <th>RHA_len</th>\n",
       "      <th>...</th>\n",
       "      <th>nGCcnt1</th>\n",
       "      <th>nGCcnt2</th>\n",
       "      <th>nGCcnt3</th>\n",
       "      <th>fGCcont1</th>\n",
       "      <th>fGCcont2</th>\n",
       "      <th>fGCcont3</th>\n",
       "      <th>MFE3</th>\n",
       "      <th>MFE4</th>\n",
       "      <th>DeepSpCas9_score</th>\n",
       "      <th>Measured_PE_efficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNMT1</td>\n",
       "      <td>EDFIG5B_DNMT1_10NT</td>\n",
       "      <td>TGGGGATTCCTGGTGCCAGAAACAGGGGTGACGGGAGGGCAGAACT...</td>\n",
       "      <td>xxxxxxxxCCTGGTGCCAGAAACAGTGGTxxxxxxxxxxxxxxxxx...</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>57.142857</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>65.144363</td>\n",
       "      <td>6.410003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DNMT1</td>\n",
       "      <td>EDFIG5B_DNMT1_10NT</td>\n",
       "      <td>TGGGGATTCCTGGTGCCAGAAACAGGGGTGACGGGAGGGCAGAACT...</td>\n",
       "      <td>xxxxxxxxCCTGGTGCCAGAAACAGTGGTGxxxxxxxxxxxxxxxx...</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>59.090909</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>65.144363</td>\n",
       "      <td>0.919506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DNMT1</td>\n",
       "      <td>EDFIG5B_DNMT1_10NT</td>\n",
       "      <td>TGGGGATTCCTGGTGCCAGAAACAGGGGTGACGGGAGGGCAGAACT...</td>\n",
       "      <td>xxxxxxxxCCTGGTGCCAGAAACAGTGGTGAxxxxxxxxxxxxxxx...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>56.521739</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>65.144363</td>\n",
       "      <td>5.100177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DNMT1</td>\n",
       "      <td>EDFIG5B_DNMT1_10NT</td>\n",
       "      <td>TGGGGATTCCTGGTGCCAGAAACAGGGGTGACGGGAGGGCAGAACT...</td>\n",
       "      <td>xxxxxxxxCCTGGTGCCAGAAACAGTGGTGACxxxxxxxxxxxxxx...</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>58.333333</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>65.144363</td>\n",
       "      <td>9.992335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DNMT1</td>\n",
       "      <td>EDFIG5B_DNMT1_10NT</td>\n",
       "      <td>TGGGGATTCCTGGTGCCAGAAACAGGGGTGACGGGAGGGCAGAACT...</td>\n",
       "      <td>xxxxxxxxCCTGGTGCCAGAAACAGTGGTGACGxxxxxxxxxxxxx...</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>58.333333</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>65.144363</td>\n",
       "      <td>3.479796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>RNF2</td>\n",
       "      <td>FIG2A_PE2_RNF2_10</td>\n",
       "      <td>GGCAGTCATCTTAGTCATTACCTGAGGTGTTCGTTGTAACTCATAT...</td>\n",
       "      <td>xxxxxxCATCTTAGTCATTACATGAGGTGTTCxxxxxxxxxxxxxx...</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>45.454545</td>\n",
       "      <td>38.461538</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.229725</td>\n",
       "      <td>3.630080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>RNF2</td>\n",
       "      <td>FIG2A_PE2_RNF2_10</td>\n",
       "      <td>GGCAGTCATCTTAGTCATTACCTGAGGTGTTCGTTGTAACTCATAT...</td>\n",
       "      <td>xxxxxxCATCTTAGTCATTACATGAGGTGTTCxxxxxxxxxxxxxx...</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>45.454545</td>\n",
       "      <td>38.461538</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.229725</td>\n",
       "      <td>6.989605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>RNF2</td>\n",
       "      <td>FIG2A_PE2_RNF2_10</td>\n",
       "      <td>GGCAGTCATCTTAGTCATTACCTGAGGTGTTCGTTGTAACTCATAT...</td>\n",
       "      <td>xxxxxTCATCTTAGTCATTACATGAGGTGTTCxxxxxxxxxxxxxx...</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>31.250000</td>\n",
       "      <td>45.454545</td>\n",
       "      <td>37.037037</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.229725</td>\n",
       "      <td>3.022388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>RNF2</td>\n",
       "      <td>FIG2A_PE2_RNF2_10</td>\n",
       "      <td>GGCAGTCATCTTAGTCATTACCTGAGGTGTTCGTTGTAACTCATAT...</td>\n",
       "      <td>xxxxGTCATCTTAGTCATTACATGAGGTGTTCxxxxxxxxxxxxxx...</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>35.294118</td>\n",
       "      <td>45.454545</td>\n",
       "      <td>39.285714</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.229725</td>\n",
       "      <td>2.146368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>RNF2</td>\n",
       "      <td>FIG2A_PE2_RNF2_10</td>\n",
       "      <td>GGCAGTCATCTTAGTCATTACCTGAGGTGTTCGTTGTAACTCATAT...</td>\n",
       "      <td>xxxxxxCATCTTAGTCATTACATGAGGTGTTxxxxxxxxxxxxxxx...</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.229725</td>\n",
       "      <td>6.623650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gene                  ID  \\\n",
       "0    DNMT1  EDFIG5B_DNMT1_10NT   \n",
       "1    DNMT1  EDFIG5B_DNMT1_10NT   \n",
       "2    DNMT1  EDFIG5B_DNMT1_10NT   \n",
       "3    DNMT1  EDFIG5B_DNMT1_10NT   \n",
       "4    DNMT1  EDFIG5B_DNMT1_10NT   \n",
       "..     ...                 ...   \n",
       "194   RNF2   FIG2A_PE2_RNF2_10   \n",
       "195   RNF2   FIG2A_PE2_RNF2_10   \n",
       "196   RNF2   FIG2A_PE2_RNF2_10   \n",
       "197   RNF2   FIG2A_PE2_RNF2_10   \n",
       "198   RNF2   FIG2A_PE2_RNF2_10   \n",
       "\n",
       "                                               WT74_On  \\\n",
       "0    TGGGGATTCCTGGTGCCAGAAACAGGGGTGACGGGAGGGCAGAACT...   \n",
       "1    TGGGGATTCCTGGTGCCAGAAACAGGGGTGACGGGAGGGCAGAACT...   \n",
       "2    TGGGGATTCCTGGTGCCAGAAACAGGGGTGACGGGAGGGCAGAACT...   \n",
       "3    TGGGGATTCCTGGTGCCAGAAACAGGGGTGACGGGAGGGCAGAACT...   \n",
       "4    TGGGGATTCCTGGTGCCAGAAACAGGGGTGACGGGAGGGCAGAACT...   \n",
       "..                                                 ...   \n",
       "194  GGCAGTCATCTTAGTCATTACCTGAGGTGTTCGTTGTAACTCATAT...   \n",
       "195  GGCAGTCATCTTAGTCATTACCTGAGGTGTTCGTTGTAACTCATAT...   \n",
       "196  GGCAGTCATCTTAGTCATTACCTGAGGTGTTCGTTGTAACTCATAT...   \n",
       "197  GGCAGTCATCTTAGTCATTACCTGAGGTGTTCGTTGTAACTCATAT...   \n",
       "198  GGCAGTCATCTTAGTCATTACCTGAGGTGTTCGTTGTAACTCATAT...   \n",
       "\n",
       "                                           Edited74_On  PBSlen  RTlen  \\\n",
       "0    xxxxxxxxCCTGGTGCCAGAAACAGTGGTxxxxxxxxxxxxxxxxx...      13      8   \n",
       "1    xxxxxxxxCCTGGTGCCAGAAACAGTGGTGxxxxxxxxxxxxxxxx...      13      9   \n",
       "2    xxxxxxxxCCTGGTGCCAGAAACAGTGGTGAxxxxxxxxxxxxxxx...      13     10   \n",
       "3    xxxxxxxxCCTGGTGCCAGAAACAGTGGTGACxxxxxxxxxxxxxx...      13     11   \n",
       "4    xxxxxxxxCCTGGTGCCAGAAACAGTGGTGACGxxxxxxxxxxxxx...      13     12   \n",
       "..                                                 ...     ...    ...   \n",
       "194  xxxxxxCATCTTAGTCATTACATGAGGTGTTCxxxxxxxxxxxxxx...      15     11   \n",
       "195  xxxxxxCATCTTAGTCATTACATGAGGTGTTCxxxxxxxxxxxxxx...      15     11   \n",
       "196  xxxxxTCATCTTAGTCATTACATGAGGTGTTCxxxxxxxxxxxxxx...      16     11   \n",
       "197  xxxxGTCATCTTAGTCATTACATGAGGTGTTCxxxxxxxxxxxxxx...      17     11   \n",
       "198  xxxxxxCATCTTAGTCATTACATGAGGTGTTxxxxxxxxxxxxxxx...      15     10   \n",
       "\n",
       "     RT-PBSlen  Edit_pos  Edit_len  RHA_len  ...  nGCcnt1  nGCcnt2  nGCcnt3  \\\n",
       "0           21         5         1        3  ...        8        4       12   \n",
       "1           22         5         1        4  ...        8        5       13   \n",
       "2           23         5         1        5  ...        8        5       13   \n",
       "3           24         5         1        6  ...        8        6       14   \n",
       "4           25         5         1        7  ...        8        7       15   \n",
       "..         ...       ...       ...      ...  ...      ...      ...      ...   \n",
       "194         26         1         1       10  ...        5        5       10   \n",
       "195         26         1         1       10  ...        5        5       10   \n",
       "196         27         1         1       10  ...        5        5       10   \n",
       "197         28         1         1       10  ...        6        5       11   \n",
       "198         25         1         1        9  ...        5        4        9   \n",
       "\n",
       "      fGCcont1   fGCcont2   fGCcont3  MFE3  MFE4  DeepSpCas9_score  \\\n",
       "0    61.538462  50.000000  57.142857  -1.7  -1.6         65.144363   \n",
       "1    61.538462  55.555556  59.090909  -1.7  -1.6         65.144363   \n",
       "2    61.538462  50.000000  56.521739  -1.7  -1.6         65.144363   \n",
       "3    61.538462  54.545455  58.333333  -1.7  -1.6         65.144363   \n",
       "4    61.538462  58.333333  60.000000  -1.7  -1.6         65.144363   \n",
       "..         ...        ...        ...   ...   ...               ...   \n",
       "194  33.333333  45.454545  38.461538  -1.1   0.0         52.229725   \n",
       "195  33.333333  45.454545  38.461538  -1.1   0.0         52.229725   \n",
       "196  31.250000  45.454545  37.037037  -1.6   0.0         52.229725   \n",
       "197  35.294118  45.454545  39.285714  -1.5   0.0         52.229725   \n",
       "198  33.333333  40.000000  36.000000  -0.2   0.0         52.229725   \n",
       "\n",
       "     Measured_PE_efficiency  \n",
       "0                  6.410003  \n",
       "1                  0.919506  \n",
       "2                  5.100177  \n",
       "3                  9.992335  \n",
       "4                  3.479796  \n",
       "..                      ...  \n",
       "194                3.630080  \n",
       "195                6.989605  \n",
       "196                3.022388  \n",
       "197                2.146368  \n",
       "198                6.623650  \n",
       "\n",
       "[199 rows x 29 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_data = pd.read_csv('../easy_prime/figure_rep/DeepPrime_ForFT_withGenes.csv')\n",
    "finetune_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38404d05-9baf-4a5b-8b5f-f6018444f118",
   "metadata": {},
   "source": [
    "### At the end of this section, you have 5 different splits of test/train data. In each of the test sets, there is roughly equal representation across all the 8 genes. Additionally, if you concatenate all the test sets together across all 5 models, you will get all the 199 points. Additionally, each test/train pair contains all 199 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "62d94fe7-aa16-4840-97e6-698fc3842ab9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 15 40\n",
      "144 15 40\n",
      "144 15 40\n",
      "144 15 40\n",
      "144 16 39\n"
     ]
    }
   ],
   "source": [
    "genes = ['RNF2', 'EMX1', 'VEGFA', 'HEK3', 'FANCF', 'DNMT1', 'HEK4', 'RUNX1']\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define the number of splits\n",
    "num_splits = 5\n",
    "\n",
    "# Initialize StratifiedKFold to ensure balanced splitting\n",
    "skf = StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Combine all gene indices into a single list\n",
    "all_gene_indices = np.concatenate(list(gene_indices.values()))\n",
    "\n",
    "\n",
    "# Create labels for each gene based on their indices\n",
    "gene_labels = np.zeros(len(all_gene_indices))\n",
    "for i, gene_name in enumerate(gene_indices.keys()):\n",
    "    gene_labels[gene_indices[gene_name]] = i\n",
    "\n",
    "# List to store train/test splits\n",
    "train_test_splits = []\n",
    "\n",
    "# Iterate over the splits\n",
    "for train_index, test_index in skf.split(all_gene_indices, gene_labels):\n",
    "    # Initialize lists to store indices for train and test sets\n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "    \n",
    "    # Split each gene's data separately\n",
    "    for gene_name, indices in gene_indices.items():\n",
    "        \n",
    "        # Divide the indices into train and test sets\n",
    "        gene_train_index = np.intersect1d(train_index, indices)\n",
    "        gene_test_index = np.intersect1d(test_index, indices)\n",
    "        \n",
    "        # Add the indices to the respective lists\n",
    "        train_indices.extend(gene_train_index)\n",
    "        test_indices.extend(gene_test_index)\n",
    "    \n",
    "    # Shuffle the indices\n",
    "    np.random.shuffle(train_indices)\n",
    "    np.random.shuffle(test_indices)\n",
    "    \n",
    "    num_validation_indices = int(0.1 * len(train_indices))                                            # I want 10% of the indices to be used for validation\n",
    "    validation_indices = np.random.choice(train_indices, size=num_validation_indices, replace=False)  # Randomly choose 10% of the indices for validation\n",
    "    train_indices = [index for index in train_indices if index not in validation_indices]             # Remove validation indices from train_indices\n",
    "    \n",
    "\n",
    "    # Append the train/test indices split to the list\n",
    "    train_test_splits.append((train_indices, validation_indices, test_indices))\n",
    "    print(len(train_indices), len(validation_indices), len(test_indices))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53730466-75ea-4701-b2f6-811db7a34086",
   "metadata": {},
   "source": [
    "### Now, for each test/train index split up, I need to:\n",
    "\n",
    "### - Take 10% of the test data for validation\n",
    "### - Create x_train, g_train, and y_train\n",
    "### - Create x_val, g_val, and y_val\n",
    "### - Create x_test, g_test, and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "8b2394d6-bd75-4fa5-b578-03eb2074db4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_wrapper(split, num_model):\n",
    "    \n",
    "    # Train and test\n",
    "    train_indices = split[0]\n",
    "    validation_indices = split[1]\n",
    "    test_indices = split[2]\n",
    "    \n",
    "    #Prepare train\n",
    "    x_train, g_train, y_train = get_training(finetune_data, train_indices, num_model)\n",
    "    \n",
    "    #Prepare validation\n",
    "    x_validation, g_validation, y_validation = get_validation(finetune_data, validation_indices, num_model)\n",
    "    \n",
    "    #Prepare test\n",
    "    x_test, g_test, y_test = get_testing(finetune_data, test_indices, num_model)\n",
    "    \n",
    "    return (x_train, g_train, y_train, x_validation, g_validation, y_validation, x_test, g_test, y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5ff8e30d-c70f-4118-bdab-994d9adac485",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_training(dataset, train_indices, num_model):\n",
    "    \n",
    "    gene_path_train = 'data/genes/' + 'endogenous_train_' + str(num_model) + '.npy'\n",
    "    \n",
    "    train_dataset = finetune_data.loc[train_indices]\n",
    "    train_dataset = train_dataset.reset_index(drop = True)  #Need to reset indices so it doesn't throw an error\n",
    "\n",
    "\n",
    "    if not os.path.isfile(gene_path_train):\n",
    "        g_train = seq_concat(train_dataset)\n",
    "        np.save(gene_path_train, g_train)\n",
    "    else:\n",
    "        g_train = np.load(gene_path_train)\n",
    "\n",
    "\n",
    "    train_features, train_target = select_cols(train_dataset)  #Trained target features \n",
    "    train_type = train_dataset.loc[:, ['type_sub', 'type_ins', 'type_del']]\n",
    "\n",
    "    mean = pd.read_csv('data/mean.csv', header=None, index_col=0)\n",
    "    std = pd.read_csv('data/std.csv', header=None, index_col=0)\n",
    "\n",
    "    mean = mean.squeeze('columns')\n",
    "    std= std.squeeze('columns')\n",
    "\n",
    "    x_train = (train_features - mean) / std\n",
    "    y_train = train_target\n",
    "    y_train = pd.concat([y_train, train_type], axis=1)\n",
    "\n",
    "    g_train = torch.tensor(g_train, dtype=torch.float32, device=device)\n",
    "    x_train = torch.tensor(x_train.to_numpy(), dtype=torch.float32, device=device)\n",
    "    y_train = torch.tensor(y_train.to_numpy(), dtype=torch.float32, device=device)\n",
    "    \n",
    "    return([x_train, g_train, y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "779342d5-6c2f-4abb-ac8c-3362938f2344",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_validation(dataset, validation_indices, num_model):\n",
    "    \n",
    "    gene_path_validation = 'data/genes/' + 'endogenous_val_' + str(num_model) + '.npy'\n",
    "    \n",
    "    validation_dataset = finetune_data.loc[validation_indices]\n",
    "    validation_dataset = validation_dataset.reset_index(drop = True)  #Need to reset indices so it doesn't throw an error\n",
    "\n",
    "\n",
    "    if not os.path.isfile(gene_path_validation):\n",
    "        g_validation = seq_concat(validation_dataset)\n",
    "        np.save(gene_path_validation, g_validation)\n",
    "    else:\n",
    "        g_validation = np.load(gene_path_validation)\n",
    "\n",
    "\n",
    "    validation_features, validation_target = select_cols(validation_dataset)  \n",
    "    validation_type = validation_dataset.loc[:, ['type_sub', 'type_ins', 'type_del']]\n",
    "\n",
    "    mean = pd.read_csv('data/mean.csv', header=None, index_col=0)\n",
    "    std = pd.read_csv('data/std.csv', header=None, index_col=0)\n",
    "\n",
    "    mean = mean.squeeze('columns')\n",
    "    std= std.squeeze('columns')\n",
    "\n",
    "    x_validation = (validation_features - mean) / std\n",
    "    y_validation = validation_target\n",
    "    y_validation = pd.concat([y_validation, validation_type], axis=1)\n",
    "\n",
    "    g_validation = torch.tensor(g_validation, dtype=torch.float32, device=device)\n",
    "    x_validation = torch.tensor(x_validation.to_numpy(), dtype=torch.float32, device=device)\n",
    "    y_validation = torch.tensor(y_validation.to_numpy(), dtype=torch.float32, device=device)\n",
    "    \n",
    "    return([x_validation, g_validation, y_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "48b000f1-d335-407b-be88-f7a11db1ef2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_testing(dataset, test_indices, num_model):\n",
    "    \n",
    "\n",
    "    gene_path_test = 'data/genes/' + 'endogenous_test' +  str(num_model) +'.npy'\n",
    "    \n",
    "    test_dataset = finetune_data.loc[test_indices]\n",
    "    test_dataset = test_dataset.reset_index(drop = True)  #Need to reset indices so it doesn't throw an error\n",
    "\n",
    "    if not os.path.isfile(gene_path_test):\n",
    "        g_test = seq_concat(test_dataset)\n",
    "        np.save(gene_path_test, g_test)\n",
    "    else:\n",
    "        g_test = np.load(gene_path_test)\n",
    "\n",
    "    test_features, test_target = select_cols(test_dataset)  #Test target features \n",
    "    test_type = test_dataset.loc[:, ['type_sub', 'type_ins', 'type_del']]\n",
    "\n",
    "    mean = pd.read_csv('data/mean.csv', header=None, index_col=0)\n",
    "    std = pd.read_csv('data/std.csv', header=None, index_col=0)\n",
    "\n",
    "    mean = mean.squeeze('columns')\n",
    "    std= std.squeeze('columns')\n",
    "\n",
    "    x_test = (test_features - mean) / std\n",
    "    y_test = test_target\n",
    "    y_test = pd.concat([y_test, test_type], axis=1)\n",
    "\n",
    "    g_test = torch.tensor(g_test, dtype=torch.float32, device=device)\n",
    "    x_test = torch.tensor(x_test.to_numpy(), dtype=torch.float32, device=device)\n",
    "    y_test = torch.tensor(y_test.to_numpy(), dtype=torch.float32, device=device)\n",
    "    \n",
    "    return([x_test, g_test, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3059da-f751-4310-b42b-1738c2f89f08",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e8efe65a-daa5-4c33-83f4-d3cbaf526b88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "import time\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "873b32f2-683d-4736-b4bd-9094456d1bae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Optuna_Trainer:\n",
    "    \n",
    "    # Initializing attributes including training and testing sets g (one-hot encoding of input sequences), x (features), and y (Measured editing efficiencies).\n",
    "    def __init__(self, model, x_train, g_train, y_train, x_y_validation, g_y_validation, y_validation): \n",
    "        self.g_train = g_train   # Training data for g\n",
    "        self.x_train = x_train   # Training data for x \n",
    "        self.y_train = y_train   # Training data for y\n",
    "        self.g_val = g_validation       # Validation data for g\n",
    "        self.x_val = x_validation       # Validation data for x\n",
    "        self.y_val = y_validation       # Validation data for y\n",
    "        self.model = model       # Call machine learning model as an attribute of the object\n",
    "        self.lr = 1e-5           # Learning rate\n",
    "        self.wd = 1e-5           # Weight decay: Weight decay should typically be same value as the learning rate\n",
    "        self.bs = 8              # Batch size \n",
    "        self.ep = 100            # Number of epochs\n",
    "        \n",
    "        # Patience represents the number of consecutive trials where the validation loss does not decrease (performance is not improved).\n",
    "        self.patience = 20       # Changing patience value to 20. \n",
    "        self.delta = 1e-4        # Delta is the threshold needed for the difference between the previous minimum loss and the validation loss.\n",
    "\n",
    "    # Set up hyperparameter search space\n",
    "    def setup_trials(self, trial):\n",
    "        \n",
    "        #Parameters that need to be searched\n",
    "        self.lr = trial.suggest_categorical(\"lr\", [1e-4,1e-3,2e-3,5e-3, 1e-2])   # Categorical values for learning rate\n",
    "        self.wd = self.lr                                                        # Assign weight decay to be the same as the learning rate\n",
    "        self.bs = trial.suggest_categorical(\"batch_size\", [8, 16, 32])           # Categorical values for batch size\n",
    "        self.ep = trial.suggest_categorical(\"num_epochs\", [50, 100, 200, 500])   # Categorical values for number of epochs\n",
    "        \n",
    "        # Fixed parameters\n",
    "        self.hs = 128                    # Hidden size\n",
    "        self.nl = 1                      # Number of GRU layers\n",
    "        self.schedule = True             # Learning rate scheduler\n",
    "        \n",
    "        # Print trial hyperparameters\n",
    "        for key, value in trial.params.items():\n",
    "            print(\"{}: {}\".format(key, value))\n",
    "    \n",
    "    # Trains the DeepPrime model based on the provided testing and training data\n",
    "    def train_model(self, trial): \n",
    "        \n",
    "        min_loss = None                   #  Stores the minimum loss, initialize with no value\n",
    "        early_stopping_counter = 0        #  Track how many consecutive epochs have occurred without improvement in the validation loss, used to prevent overfitting.\n",
    "\n",
    "        #Trial object is created when Optuna generates a study object, so it's not something to explicitly point to\n",
    "        self.setup_trials(trial) # Sets up the trial with a set of hyperparameters derived from the setup_trials function\n",
    "\n",
    "\n",
    "        # Prepare the training data to run through the model\n",
    "        train_dataset = GeneFeatureDataset(self.g_train, self.x_train, self.y_train) \n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.bs, shuffle=True, drop_last=True) \n",
    "\n",
    "        # Prepare the testing and validation datasets\n",
    "        val_dataset = GeneFeatureDataset(self.g_val, self.x_val, self.y_val) \n",
    "        val_loader = DataLoader(val_dataset, batch_size=self.bs, shuffle=True) # Q: Shuffle?\n",
    "\n",
    "        optimizer = optim.AdamW(self.model.parameters(), lr=self.lr, weight_decay=self.wd)   # Sets up optimizer, I am also using AdamW\n",
    "        optimizer.zero_grad()  # Zeroes out gradients, kind of a \"hack\" where optimization is actually better when gradients are not stored\n",
    "        \n",
    "        criterion = BalancedMSELoss() # Loss function used in DeepPrime\n",
    "\n",
    "        # print(\"epoch\\ttrain_corr\\ttrain_loss\\ttrue_auc\\tpred_auc\\tval_corr\\tval_loss\\telapsed_time\")\n",
    "        for epoch in range(self.ep): # self.ep is the number of epochs, so here we are iterating through the epochs\n",
    "            \n",
    "            # Train\n",
    "            self.model.train()  # Sets model in training mode. Make sure to use self.model because model is now an attribute of the class itself.\n",
    "            \n",
    "            train_loss = []    # List that will keep track of the loss across the entire epoch\n",
    "            train_count = 0    # Number of samples processed in epoch\n",
    "    \n",
    "\n",
    "            # Works through each batch of data set up by the train_loader\n",
    "            for i, (g_batch, x_batch, y_batch) in enumerate(train_loader):\n",
    "                g_batch, x_batch, y_batch = g_batch.cuda(), x_batch.cuda(), y_batch.cuda() # We are on GPU, so move tensors to GPU\n",
    "\n",
    "                # Update values for all three tensors. Following permutations used in DeepPrime.\n",
    "                g_batch = g_batch.permute((0, 3, 1, 2))\n",
    "                x_batch = x_batch\n",
    "                y_batch = y_batch.reshape(-1, 4)\n",
    "\n",
    "\n",
    "                optimizer.zero_grad()  #Zero out gradient for each batch\n",
    "\n",
    "                output = self.model(g_batch, x_batch) # Send g and x through the model\n",
    "\n",
    "                total_loss = criterion(output, y_batch) # Calculate the loss between the model output and the actual measured efficiencies\n",
    "\n",
    "                total_loss.backward() # Computes gradients of the loss with repsect to the model parameters\n",
    "                optimizer.step()  # Applies optimization to update parameters\n",
    "\n",
    "                train_loss.append(x_batch.size(0) * total_loss.detach().cpu().numpy()) # Multiplies batch-loss by batch size to normalize for different sized batches during training\n",
    "                train_count += x_batch.size(0)  # Updates number of samples processed in the epoch\n",
    "\n",
    "            train_loss = sum(train_loss) / train_count  # train_loss now represents the average training loss across batches for the ENTIRE epoch\n",
    "\n",
    "\n",
    "            # Validation\n",
    "            self.model.eval()  # Set model in evaluation mode\n",
    "            \n",
    "            val_loss = []\n",
    "            val_count = 0\n",
    "\n",
    "            # Same as with training batches\n",
    "            for i, (g_batch, x_batch, y_batch) in enumerate(val_loader):\n",
    "                g_batch, x_batch, y_batch = g_batch.cuda(), x_batch.cuda(), y_batch.cuda()\n",
    "\n",
    "                g_batch = g_batch.permute((0, 3, 1, 2))\n",
    "                x_batch = x_batch\n",
    "                y_batch = y_batch.reshape(-1, 4)\n",
    "                \n",
    "                output = self.model(g_batch, x_batch)  #Run validation data through model\n",
    "\n",
    "                loss = criterion(output, y_batch)\n",
    "                \n",
    "                \n",
    "                val_loss.append(x_batch.size(0) * loss.detach().cpu().numpy())\n",
    "                val_count += x_batch.size(0)\n",
    "\n",
    "            val_loss = sum(val_loss) / val_count\n",
    "\n",
    "\n",
    "            # Summary of training progress\n",
    "            # print(\"{}\\t{:.4f}\\t{:.4f}\".format(epoch, train_loss, val_loss))\n",
    "\n",
    "            trial.report(val_loss, epoch) # Reports the result of the current epoch to Optuna, so Optuna can keep track of model performance throughout the trial.\n",
    "            \n",
    "\n",
    "            if min_loss is None:\n",
    "                min_loss = val_loss  \n",
    "            elif min_loss - val_loss > self.delta:                    # If the difference between the previous minimum loss and the current validation loss is greater than delta, update values\n",
    "                min_loss = val_loss                                   # Set the new minimum loss to current validation loss\n",
    "                early_stopping_counter = 0                            # Reset to 0, indicating no consecutive epochs with increasing validation loss.\n",
    "            elif min_loss - val_loss < self.delta:                    # No improvement in validation loss\n",
    "                early_stopping_counter += 1                           # Consecutive epoch for which there is no improvement on validation loss\n",
    "                if early_stopping_counter >= self.patience:           # At this point, further training is unlikely to improve/lower validation loss, so break\n",
    "                    break\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "        return val_loss # #Returns the loss across the epochs, as this is the value we want to minimize\n",
    "\n",
    "    def exec_study(self):\n",
    "        study = optuna.create_study()                      # Creates Optuna study object, maximizing correlation\n",
    "        study.optimize(self.train_model, n_trials=30)      # Runs train_model function n_trials times\n",
    "        return self.print_result(study)                    # Prints out hyperparameters used for combination that generated lowest validation loss.\n",
    "    \n",
    "    def print_result(self, study):\n",
    "        pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "        complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "        print(\"Study statistics:\")\n",
    "        print(\"Number of finished trials:\", len(study.trials))\n",
    "        print(\"Number of pruned trials:\", len(pruned_trials))\n",
    "        print(\"Number of complete trials:\", len(complete_trials))\n",
    "\n",
    "        print(\"Best trial:\")\n",
    "        best_trial = study.best_trial\n",
    "\n",
    "        print(\"Value: \", best_trial.value)\n",
    "\n",
    "        best_params = {}\n",
    "        print(\"Params:\")\n",
    "        for key, value in best_trial.params.items():\n",
    "            print(\"{}: {}\".format(key, value))\n",
    "            best_params[key] = value\n",
    "        for key, value in best_trial.user_attrs.items():\n",
    "            print(\"{}: {}\".format(key, value))\n",
    "            best_params[key] = value\n",
    "\n",
    "        return best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "0513f736-297d-498e-aaa0-c4423c9f9b72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model 0\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:09:16,513] A new study created in memory with name: no-name-c20b97a5-dfbb-4dab-96c6-12d43d4e6763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:09:37,743] Trial 0 finished with value: 1.1988555431365966 and parameters: {'lr': 0.0001, 'batch_size': 8, 'num_epochs': 200}. Best is trial 0 with value: 1.1988555431365966.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 16\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:09:41,212] Trial 1 finished with value: 0.21060101687908173 and parameters: {'lr': 0.01, 'batch_size': 16, 'num_epochs': 200}. Best is trial 1 with value: 0.21060101687908173.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 16\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:09:42,525] Trial 2 finished with value: 0.2966647744178772 and parameters: {'lr': 0.002, 'batch_size': 16, 'num_epochs': 50}. Best is trial 1 with value: 0.21060101687908173.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 8\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:09:46,399] Trial 3 finished with value: 0.275040528178215 and parameters: {'lr': 0.001, 'batch_size': 8, 'num_epochs': 50}. Best is trial 1 with value: 0.21060101687908173.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 8\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:09:50,436] Trial 4 finished with value: 0.3810619672139486 and parameters: {'lr': 0.001, 'batch_size': 8, 'num_epochs': 100}. Best is trial 1 with value: 0.21060101687908173.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:09:51,368] Trial 5 finished with value: 0.42140257358551025 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 100}. Best is trial 1 with value: 0.21060101687908173.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 16\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:09:53,356] Trial 6 finished with value: 0.3801342844963074 and parameters: {'lr': 0.005, 'batch_size': 16, 'num_epochs': 100}. Best is trial 1 with value: 0.21060101687908173.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:09:54,109] Trial 7 finished with value: 0.40259143710136414 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 50}. Best is trial 1 with value: 0.21060101687908173.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 8\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:09:58,014] Trial 8 finished with value: 0.3713065574566523 and parameters: {'lr': 0.002, 'batch_size': 8, 'num_epochs': 50}. Best is trial 1 with value: 0.21060101687908173.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 16\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:09:59,317] Trial 9 finished with value: 0.4220978617668152 and parameters: {'lr': 0.005, 'batch_size': 16, 'num_epochs': 200}. Best is trial 1 with value: 0.21060101687908173.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:10:01,072] Trial 10 finished with value: 0.45058533549308777 and parameters: {'lr': 0.01, 'batch_size': 16, 'num_epochs': 500}. Best is trial 1 with value: 0.21060101687908173.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:10:05,318] Trial 11 finished with value: 0.3608455667893092 and parameters: {'lr': 0.001, 'batch_size': 8, 'num_epochs': 200}. Best is trial 1 with value: 0.21060101687908173.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:10:09,904] Trial 12 finished with value: 0.5076001286506653 and parameters: {'lr': 0.01, 'batch_size': 16, 'num_epochs': 500}. Best is trial 1 with value: 0.21060101687908173.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 8\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:10:15,128] Trial 13 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 32\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:10:16,348] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 16\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:10:17,956] Trial 15 finished with value: 0.36360517144203186 and parameters: {'lr': 0.01, 'batch_size': 16, 'num_epochs': 50}. Best is trial 1 with value: 0.21060101687908173.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:10:20,623] Trial 16 finished with value: 0.4065647085507711 and parameters: {'lr': 0.001, 'batch_size': 8, 'num_epochs': 200}. Best is trial 1 with value: 0.21060101687908173.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 8\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:10:26,682] Trial 17 finished with value: 0.2679513196150462 and parameters: {'lr': 0.01, 'batch_size': 8, 'num_epochs': 500}. Best is trial 1 with value: 0.21060101687908173.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:10:28,042] Trial 18 finished with value: 0.5522788166999817 and parameters: {'lr': 0.01, 'batch_size': 16, 'num_epochs': 500}. Best is trial 1 with value: 0.21060101687908173.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:10:29,011] Trial 19 finished with value: 0.37028729915618896 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 500}. Best is trial 1 with value: 0.21060101687908173.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 8\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:10:35,080] Trial 20 finished with value: 0.30414826075236 and parameters: {'lr': 0.01, 'batch_size': 8, 'num_epochs': 500}. Best is trial 1 with value: 0.21060101687908173.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 8\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:10:37,747] Trial 21 finished with value: 0.3941822052001953 and parameters: {'lr': 0.001, 'batch_size': 8, 'num_epochs': 500}. Best is trial 1 with value: 0.21060101687908173.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:10:42,524] Trial 22 finished with value: 0.1986317257086436 and parameters: {'lr': 0.01, 'batch_size': 8, 'num_epochs': 200}. Best is trial 22 with value: 0.1986317257086436.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:10:45,075] Trial 23 finished with value: 0.2824838598569234 and parameters: {'lr': 0.01, 'batch_size': 8, 'num_epochs': 200}. Best is trial 22 with value: 0.1986317257086436.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:10:49,855] Trial 24 finished with value: 0.23869835138320922 and parameters: {'lr': 0.01, 'batch_size': 8, 'num_epochs': 200}. Best is trial 22 with value: 0.1986317257086436.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 16\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:10:51,226] Trial 25 finished with value: 0.25236040353775024 and parameters: {'lr': 0.01, 'batch_size': 16, 'num_epochs': 200}. Best is trial 22 with value: 0.1986317257086436.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:10:54,249] Trial 26 finished with value: 0.27672207951545713 and parameters: {'lr': 0.0001, 'batch_size': 8, 'num_epochs': 200}. Best is trial 22 with value: 0.1986317257086436.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:10:59,518] Trial 27 finished with value: 0.3432760119438171 and parameters: {'lr': 0.01, 'batch_size': 8, 'num_epochs': 200}. Best is trial 22 with value: 0.1986317257086436.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 32\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:00,306] Trial 28 finished with value: 0.4047876000404358 and parameters: {'lr': 0.002, 'batch_size': 32, 'num_epochs': 200}. Best is trial 22 with value: 0.1986317257086436.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 16\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:02,548] Trial 29 pruned. \n",
      "[I 2024-02-26 16:11:02,741] A new study created in memory with name: no-name-822cbfae-5685-473f-827a-1aa4467cfd66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics:\n",
      "Number of finished trials: 30\n",
      "Number of pruned trials: 3\n",
      "Number of complete trials: 27\n",
      "Best trial:\n",
      "Value:  0.1986317257086436\n",
      "Params:\n",
      "lr: 0.01\n",
      "batch_size: 8\n",
      "num_epochs: 200\n",
      "Model 0 complete.\n",
      "Training Model 1\n",
      "cuda:0\n",
      "lr: 0.001\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:06,423] Trial 0 finished with value: 0.7866350412368774 and parameters: {'lr': 0.001, 'batch_size': 16, 'num_epochs': 500}. Best is trial 0 with value: 0.7866350412368774.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 32\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:09,295] Trial 1 finished with value: 0.3230607211589813 and parameters: {'lr': 0.002, 'batch_size': 32, 'num_epochs': 200}. Best is trial 1 with value: 0.3230607211589813.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 16\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:11,599] Trial 2 finished with value: 0.27430015802383423 and parameters: {'lr': 0.005, 'batch_size': 16, 'num_epochs': 200}. Best is trial 2 with value: 0.27430015802383423.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 16\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:13,712] Trial 3 finished with value: 0.23788751661777496 and parameters: {'lr': 0.001, 'batch_size': 16, 'num_epochs': 100}. Best is trial 3 with value: 0.23788751661777496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:15,149] Trial 4 finished with value: 0.2948352098464966 and parameters: {'lr': 0.005, 'batch_size': 16, 'num_epochs': 500}. Best is trial 3 with value: 0.23788751661777496.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:17,164] Trial 5 finished with value: 0.18866918981075287 and parameters: {'lr': 0.0001, 'batch_size': 32, 'num_epochs': 500}. Best is trial 5 with value: 0.18866918981075287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:19,560] Trial 6 finished with value: 0.2558642327785492 and parameters: {'lr': 0.01, 'batch_size': 16, 'num_epochs': 500}. Best is trial 5 with value: 0.18866918981075287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 16\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:21,863] Trial 7 finished with value: 0.255921334028244 and parameters: {'lr': 0.01, 'batch_size': 16, 'num_epochs': 50}. Best is trial 5 with value: 0.18866918981075287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:24,038] Trial 8 finished with value: 0.23674340546131134 and parameters: {'lr': 0.0001, 'batch_size': 16, 'num_epochs': 500}. Best is trial 5 with value: 0.18866918981075287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:26,217] Trial 9 finished with value: 0.2001221776008606 and parameters: {'lr': 0.001, 'batch_size': 16, 'num_epochs': 500}. Best is trial 5 with value: 0.18866918981075287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 32\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:27,426] Trial 10 finished with value: 0.21434679627418518 and parameters: {'lr': 0.0001, 'batch_size': 32, 'num_epochs': 50}. Best is trial 5 with value: 0.18866918981075287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 8\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:30,009] Trial 11 finished with value: 0.276794175306956 and parameters: {'lr': 0.001, 'batch_size': 8, 'num_epochs': 500}. Best is trial 5 with value: 0.18866918981075287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:31,215] Trial 12 finished with value: 0.22894124686717987 and parameters: {'lr': 0.0001, 'batch_size': 32, 'num_epochs': 100}. Best is trial 5 with value: 0.18866918981075287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 8\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:34,840] Trial 13 finished with value: 0.33048041462898253 and parameters: {'lr': 0.002, 'batch_size': 8, 'num_epochs': 500}. Best is trial 5 with value: 0.18866918981075287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:36,653] Trial 14 finished with value: 0.20489643514156342 and parameters: {'lr': 0.001, 'batch_size': 32, 'num_epochs': 500}. Best is trial 5 with value: 0.18866918981075287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:37,872] Trial 15 finished with value: 0.2049364447593689 and parameters: {'lr': 0.0001, 'batch_size': 32, 'num_epochs': 500}. Best is trial 5 with value: 0.18866918981075287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 8\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:41,311] Trial 16 finished with value: 0.21937991976737975 and parameters: {'lr': 0.001, 'batch_size': 8, 'num_epochs': 50}. Best is trial 5 with value: 0.18866918981075287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 32\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:42,606] Trial 17 finished with value: 0.20962265133857727 and parameters: {'lr': 0.0001, 'batch_size': 32, 'num_epochs': 200}. Best is trial 5 with value: 0.18866918981075287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:44,083] Trial 18 finished with value: 0.13790684938430786 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 100}. Best is trial 18 with value: 0.13790684938430786.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:44,752] Trial 19 finished with value: 0.12963810563087463 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 100}. Best is trial 19 with value: 0.12963810563087463.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:45,426] Trial 20 finished with value: 0.13604867458343506 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 100}. Best is trial 19 with value: 0.12963810563087463.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:46,631] Trial 21 finished with value: 0.19182689487934113 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 100}. Best is trial 19 with value: 0.12963810563087463.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:47,331] Trial 22 finished with value: 0.11764371395111084 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 100}. Best is trial 22 with value: 0.11764371395111084.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:47,999] Trial 23 finished with value: 0.14245808124542236 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 100}. Best is trial 22 with value: 0.11764371395111084.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:48,758] Trial 24 finished with value: 0.1247195154428482 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 100}. Best is trial 22 with value: 0.11764371395111084.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:49,515] Trial 25 finished with value: 0.12132792919874191 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 100}. Best is trial 22 with value: 0.11764371395111084.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:50,832] Trial 26 finished with value: 0.1676846593618393 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 100}. Best is trial 22 with value: 0.11764371395111084.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 8\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:57,884] Trial 27 finished with value: 0.19068645785252253 and parameters: {'lr': 0.01, 'batch_size': 8, 'num_epochs': 100}. Best is trial 22 with value: 0.11764371395111084.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:11:58,949] Trial 28 finished with value: 0.16213050484657288 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 100}. Best is trial 22 with value: 0.11764371395111084.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:12:00,832] Trial 29 finished with value: 0.16979245841503143 and parameters: {'lr': 0.002, 'batch_size': 32, 'num_epochs': 100}. Best is trial 22 with value: 0.11764371395111084.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics:\n",
      "Number of finished trials: 30\n",
      "Number of pruned trials: 0\n",
      "Number of complete trials: 30\n",
      "Best trial:\n",
      "Value:  0.11764371395111084\n",
      "Params:\n",
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 100\n",
      "Model 1 complete.\n",
      "Training Model 2\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:12:01,060] A new study created in memory with name: no-name-27d22b8b-a33a-471d-a6c5-314734188908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 16\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:12:06,678] Trial 0 finished with value: 0.5663038492202759 and parameters: {'lr': 0.002, 'batch_size': 16, 'num_epochs': 100}. Best is trial 0 with value: 0.5663038492202759.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 16\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:12:08,049] Trial 1 finished with value: 0.622528612613678 and parameters: {'lr': 0.0001, 'batch_size': 16, 'num_epochs': 200}. Best is trial 0 with value: 0.5663038492202759.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 8\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:12:12,816] Trial 2 finished with value: 0.46252057552337644 and parameters: {'lr': 0.005, 'batch_size': 8, 'num_epochs': 50}. Best is trial 2 with value: 0.46252057552337644.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 8\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:12:16,584] Trial 3 finished with value: 0.5134413401285808 and parameters: {'lr': 0.002, 'batch_size': 8, 'num_epochs': 50}. Best is trial 2 with value: 0.46252057552337644.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 16\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:12:18,143] Trial 4 finished with value: 0.5615721940994263 and parameters: {'lr': 0.001, 'batch_size': 16, 'num_epochs': 100}. Best is trial 2 with value: 0.46252057552337644.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:12:19,881] Trial 5 finished with value: 0.746796727180481 and parameters: {'lr': 0.005, 'batch_size': 16, 'num_epochs': 500}. Best is trial 2 with value: 0.46252057552337644.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 8\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:12:25,013] Trial 6 finished with value: 0.6307670434316 and parameters: {'lr': 0.002, 'batch_size': 8, 'num_epochs': 500}. Best is trial 2 with value: 0.46252057552337644.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 8\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:12:30,111] Trial 7 finished with value: 0.5640026092529297 and parameters: {'lr': 0.005, 'batch_size': 8, 'num_epochs': 100}. Best is trial 2 with value: 0.46252057552337644.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 8\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:12:33,184] Trial 8 finished with value: 0.4331672747929891 and parameters: {'lr': 0.005, 'batch_size': 8, 'num_epochs': 50}. Best is trial 8 with value: 0.4331672747929891.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 16\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:12:38,207] Trial 9 finished with value: 0.3598206341266632 and parameters: {'lr': 0.01, 'batch_size': 16, 'num_epochs': 200}. Best is trial 9 with value: 0.3598206341266632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:12:38,996] Trial 10 finished with value: 0.4762710928916931 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 200}. Best is trial 9 with value: 0.3598206341266632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:12:39,753] Trial 11 finished with value: 0.6225842833518982 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 50}. Best is trial 9 with value: 0.3598206341266632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:12:49,858] Trial 12 finished with value: 0.21166424850622814 and parameters: {'lr': 0.01, 'batch_size': 8, 'num_epochs': 200}. Best is trial 12 with value: 0.21166424850622814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 16\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:12:52,517] Trial 13 finished with value: 0.27021417021751404 and parameters: {'lr': 0.01, 'batch_size': 16, 'num_epochs': 200}. Best is trial 12 with value: 0.21166424850622814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:12:53,159] Trial 14 finished with value: 0.28649699687957764 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 200}. Best is trial 12 with value: 0.21166424850622814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 16\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:12:54,653] Trial 15 finished with value: 0.27269992232322693 and parameters: {'lr': 0.01, 'batch_size': 16, 'num_epochs': 200}. Best is trial 12 with value: 0.21166424850622814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:12:58,535] Trial 16 finished with value: 0.33226567804813384 and parameters: {'lr': 0.001, 'batch_size': 8, 'num_epochs': 200}. Best is trial 12 with value: 0.21166424850622814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 16\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:13:01,233] Trial 17 finished with value: 0.31476300954818726 and parameters: {'lr': 0.0001, 'batch_size': 16, 'num_epochs': 200}. Best is trial 12 with value: 0.21166424850622814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:13:05,721] Trial 18 finished with value: 0.30126662651697794 and parameters: {'lr': 0.01, 'batch_size': 8, 'num_epochs': 200}. Best is trial 12 with value: 0.21166424850622814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:13:06,421] Trial 19 finished with value: 0.32170894742012024 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 500}. Best is trial 12 with value: 0.21166424850622814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:13:10,823] Trial 20 finished with value: 0.2490460604429245 and parameters: {'lr': 0.01, 'batch_size': 8, 'num_epochs': 200}. Best is trial 12 with value: 0.21166424850622814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:13:14,706] Trial 21 finished with value: 0.2593771626551946 and parameters: {'lr': 0.01, 'batch_size': 8, 'num_epochs': 200}. Best is trial 12 with value: 0.21166424850622814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:13:19,081] Trial 22 finished with value: 0.32122812072436013 and parameters: {'lr': 0.01, 'batch_size': 8, 'num_epochs': 200}. Best is trial 12 with value: 0.21166424850622814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:13:23,488] Trial 23 finished with value: 0.35892202854156496 and parameters: {'lr': 0.01, 'batch_size': 8, 'num_epochs': 200}. Best is trial 12 with value: 0.21166424850622814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:13:36,763] Trial 24 finished with value: 0.23747006356716155 and parameters: {'lr': 0.0001, 'batch_size': 8, 'num_epochs': 200}. Best is trial 12 with value: 0.21166424850622814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:13:41,316] Trial 25 finished with value: 0.23108504017194112 and parameters: {'lr': 0.0001, 'batch_size': 8, 'num_epochs': 200}. Best is trial 12 with value: 0.21166424850622814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:13:45,820] Trial 26 finished with value: 0.2324917753537496 and parameters: {'lr': 0.0001, 'batch_size': 8, 'num_epochs': 200}. Best is trial 12 with value: 0.21166424850622814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:13:50,383] Trial 27 finished with value: 0.23446685671806336 and parameters: {'lr': 0.0001, 'batch_size': 8, 'num_epochs': 100}. Best is trial 12 with value: 0.21166424850622814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:13:54,871] Trial 28 finished with value: 0.23557115594546 and parameters: {'lr': 0.0001, 'batch_size': 8, 'num_epochs': 500}. Best is trial 12 with value: 0.21166424850622814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:13:59,360] Trial 29 finished with value: 0.2368936578432719 and parameters: {'lr': 0.0001, 'batch_size': 8, 'num_epochs': 100}. Best is trial 12 with value: 0.21166424850622814.\n",
      "[I 2024-02-26 16:13:59,546] A new study created in memory with name: no-name-e43c6071-76a3-4680-af5c-d8081c6679a9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics:\n",
      "Number of finished trials: 30\n",
      "Number of pruned trials: 0\n",
      "Number of complete trials: 30\n",
      "Best trial:\n",
      "Value:  0.21166424850622814\n",
      "Params:\n",
      "lr: 0.01\n",
      "batch_size: 8\n",
      "num_epochs: 200\n",
      "Model 2 complete.\n",
      "Training Model 3\n",
      "cuda:0\n",
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:04,454] Trial 0 finished with value: 5.8170064926147464 and parameters: {'lr': 0.0001, 'batch_size': 8, 'num_epochs': 100}. Best is trial 0 with value: 5.8170064926147464.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 16\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:07,145] Trial 1 finished with value: 0.8548843264579773 and parameters: {'lr': 0.001, 'batch_size': 16, 'num_epochs': 100}. Best is trial 1 with value: 0.8548843264579773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:08,985] Trial 2 finished with value: 0.42852455377578735 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 200}. Best is trial 2 with value: 0.42852455377578735.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:10,328] Trial 3 finished with value: 0.35593298077583313 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 200}. Best is trial 3 with value: 0.35593298077583313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 32\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:10,970] Trial 4 finished with value: 0.4397304058074951 and parameters: {'lr': 0.0001, 'batch_size': 32, 'num_epochs': 50}. Best is trial 3 with value: 0.35593298077583313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 8\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:13,777] Trial 5 finished with value: 0.3938293178876241 and parameters: {'lr': 0.001, 'batch_size': 8, 'num_epochs': 50}. Best is trial 3 with value: 0.35593298077583313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 16\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:16,461] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:19,272] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 16\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:20,637] Trial 8 finished with value: 0.5221924185752869 and parameters: {'lr': 0.001, 'batch_size': 16, 'num_epochs': 100}. Best is trial 3 with value: 0.35593298077583313.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 32\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:21,945] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:22,932] Trial 10 finished with value: 0.28539252281188965 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 200}. Best is trial 10 with value: 0.28539252281188965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:23,755] Trial 11 finished with value: 0.564919650554657 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 200}. Best is trial 10 with value: 0.28539252281188965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:24,396] Trial 12 finished with value: 0.45419129729270935 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 200}. Best is trial 10 with value: 0.28539252281188965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:25,675] Trial 13 finished with value: 0.40705010294914246 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 500}. Best is trial 10 with value: 0.28539252281188965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 32\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:26,375] Trial 14 finished with value: 0.33427926898002625 and parameters: {'lr': 0.002, 'batch_size': 32, 'num_epochs': 200}. Best is trial 10 with value: 0.28539252281188965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 32\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:27,077] Trial 15 finished with value: 0.35501909255981445 and parameters: {'lr': 0.002, 'batch_size': 32, 'num_epochs': 200}. Best is trial 10 with value: 0.28539252281188965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:27,778] Trial 16 finished with value: 0.35422661900520325 and parameters: {'lr': 0.002, 'batch_size': 32, 'num_epochs': 500}. Best is trial 10 with value: 0.28539252281188965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 32\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:28,479] Trial 17 finished with value: 0.35912275314331055 and parameters: {'lr': 0.002, 'batch_size': 32, 'num_epochs': 200}. Best is trial 10 with value: 0.28539252281188965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 16\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:30,779] Trial 18 finished with value: 0.391791969537735 and parameters: {'lr': 0.01, 'batch_size': 16, 'num_epochs': 200}. Best is trial 10 with value: 0.28539252281188965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:33,580] Trial 19 finished with value: 0.535291322072347 and parameters: {'lr': 0.002, 'batch_size': 8, 'num_epochs': 200}. Best is trial 10 with value: 0.28539252281188965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:34,886] Trial 20 finished with value: 0.4308788478374481 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 500}. Best is trial 10 with value: 0.28539252281188965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:35,590] Trial 21 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:36,294] Trial 22 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:37,004] Trial 23 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:37,715] Trial 24 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:38,425] Trial 25 finished with value: 0.29741740226745605 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 200}. Best is trial 10 with value: 0.28539252281188965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:39,827] Trial 26 finished with value: 0.5295068025588989 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 200}. Best is trial 10 with value: 0.28539252281188965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:40,530] Trial 27 finished with value: 0.33166295289993286 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 200}. Best is trial 10 with value: 0.28539252281188965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 16\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:42,513] Trial 28 finished with value: 0.4581485688686371 and parameters: {'lr': 0.01, 'batch_size': 16, 'num_epochs': 200}. Best is trial 10 with value: 0.28539252281188965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 8\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:46,046] Trial 29 finished with value: 0.7077116072177887 and parameters: {'lr': 0.01, 'batch_size': 8, 'num_epochs': 100}. Best is trial 10 with value: 0.28539252281188965.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics:\n",
      "Number of finished trials: 30\n",
      "Number of pruned trials: 7\n",
      "Number of complete trials: 23\n",
      "Best trial:\n",
      "Value:  0.28539252281188965\n",
      "Params:\n",
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 200\n",
      "Model 3 complete.\n",
      "Training Model 4\n",
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:46,293] A new study created in memory with name: no-name-cc9f89a1-a28e-4ffe-b175-c03548e697c6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 16\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:49,912] Trial 0 finished with value: 0.5162650346755981 and parameters: {'lr': 0.01, 'batch_size': 16, 'num_epochs': 200}. Best is trial 0 with value: 0.5162650346755981.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:50,978] Trial 1 finished with value: 0.21270005404949188 and parameters: {'lr': 0.002, 'batch_size': 32, 'num_epochs': 100}. Best is trial 1 with value: 0.21270005404949188.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 8\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:55,663] Trial 2 finished with value: 0.3406253829598427 and parameters: {'lr': 0.002, 'batch_size': 8, 'num_epochs': 500}. Best is trial 1 with value: 0.21270005404949188.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 16\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:14:59,362] Trial 3 finished with value: 0.2885979413986206 and parameters: {'lr': 0.002, 'batch_size': 16, 'num_epochs': 500}. Best is trial 1 with value: 0.21270005404949188.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 16\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:15:01,376] Trial 4 finished with value: 0.28834986686706543 and parameters: {'lr': 0.0001, 'batch_size': 16, 'num_epochs': 200}. Best is trial 1 with value: 0.21270005404949188.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 16\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:15:04,059] Trial 5 finished with value: 0.26700156927108765 and parameters: {'lr': 0.001, 'batch_size': 16, 'num_epochs': 200}. Best is trial 1 with value: 0.21270005404949188.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 8\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:15:08,231] Trial 6 finished with value: 0.21108996868133545 and parameters: {'lr': 0.005, 'batch_size': 8, 'num_epochs': 500}. Best is trial 6 with value: 0.21108996868133545.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 16\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:15:10,982] Trial 7 finished with value: 0.2833362817764282 and parameters: {'lr': 0.001, 'batch_size': 16, 'num_epochs': 100}. Best is trial 6 with value: 0.21108996868133545.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:15:11,808] Trial 8 finished with value: 0.27525392174720764 and parameters: {'lr': 0.001, 'batch_size': 32, 'num_epochs': 500}. Best is trial 6 with value: 0.21108996868133545.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 8\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:15:14,372] Trial 9 finished with value: 0.5297787487506866 and parameters: {'lr': 0.01, 'batch_size': 8, 'num_epochs': 100}. Best is trial 6 with value: 0.21108996868133545.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 8\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:15:18,888] Trial 10 finished with value: 0.4187569171190262 and parameters: {'lr': 0.005, 'batch_size': 8, 'num_epochs': 50}. Best is trial 6 with value: 0.21108996868133545.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:15:20,512] Trial 11 finished with value: 0.3041975498199463 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 100}. Best is trial 6 with value: 0.21108996868133545.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 32\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:15:21,365] Trial 12 finished with value: 0.27789855003356934 and parameters: {'lr': 0.002, 'batch_size': 32, 'num_epochs': 50}. Best is trial 6 with value: 0.21108996868133545.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:15:22,129] Trial 13 finished with value: 0.28823617100715637 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 100}. Best is trial 6 with value: 0.21108996868133545.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:15:27,723] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:15:28,850] Trial 15 finished with value: 0.2897830009460449 and parameters: {'lr': 0.002, 'batch_size': 32, 'num_epochs': 100}. Best is trial 6 with value: 0.21108996868133545.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 8\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:15:33,410] Trial 16 finished with value: 0.3528554439544678 and parameters: {'lr': 0.005, 'batch_size': 8, 'num_epochs': 500}. Best is trial 6 with value: 0.21108996868133545.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 8\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:15:37,915] Trial 17 finished with value: 0.28202739357948303 and parameters: {'lr': 0.002, 'batch_size': 8, 'num_epochs': 50}. Best is trial 6 with value: 0.21108996868133545.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:15:38,981] Trial 18 finished with value: 0.25700974464416504 and parameters: {'lr': 0.005, 'batch_size': 32, 'num_epochs': 100}. Best is trial 6 with value: 0.21108996868133545.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "batch_size: 8\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:15:44,631] Trial 19 finished with value: 0.2588166743516922 and parameters: {'lr': 0.0001, 'batch_size': 8, 'num_epochs': 500}. Best is trial 6 with value: 0.21108996868133545.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:15:45,486] Trial 20 finished with value: 0.23319709300994873 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 500}. Best is trial 6 with value: 0.21108996868133545.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:15:46,162] Trial 21 finished with value: 0.25855347514152527 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 500}. Best is trial 6 with value: 0.21108996868133545.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:15:47,377] Trial 22 finished with value: 0.2746475338935852 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 500}. Best is trial 6 with value: 0.21108996868133545.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:15:48,410] Trial 23 finished with value: 0.280463844537735 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 500}. Best is trial 6 with value: 0.21108996868133545.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:15:49,293] Trial 24 finished with value: 0.27432358264923096 and parameters: {'lr': 0.002, 'batch_size': 32, 'num_epochs': 500}. Best is trial 6 with value: 0.21108996868133545.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:15:49,996] Trial 25 finished with value: 0.3162961006164551 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 100}. Best is trial 6 with value: 0.21108996868133545.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:15:54,556] Trial 26 finished with value: 0.30401624739170074 and parameters: {'lr': 0.005, 'batch_size': 8, 'num_epochs': 200}. Best is trial 6 with value: 0.21108996868133545.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002\n",
      "batch_size: 32\n",
      "num_epochs: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:15:55,440] Trial 27 finished with value: 0.24563294649124146 and parameters: {'lr': 0.002, 'batch_size': 32, 'num_epochs': 50}. Best is trial 6 with value: 0.21108996868133545.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.01\n",
      "batch_size: 32\n",
      "num_epochs: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:15:56,297] Trial 28 finished with value: 0.262162983417511 and parameters: {'lr': 0.01, 'batch_size': 32, 'num_epochs': 500}. Best is trial 6 with value: 0.21108996868133545.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.005\n",
      "batch_size: 8\n",
      "num_epochs: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-26 16:16:02,949] Trial 29 finished with value: 0.27155306935310364 and parameters: {'lr': 0.005, 'batch_size': 8, 'num_epochs': 200}. Best is trial 6 with value: 0.21108996868133545.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics:\n",
      "Number of finished trials: 30\n",
      "Number of pruned trials: 1\n",
      "Number of complete trials: 29\n",
      "Best trial:\n",
      "Value:  0.21108996868133545\n",
      "Params:\n",
      "lr: 0.005\n",
      "batch_size: 8\n",
      "num_epochs: 500\n",
      "Model 4 complete.\n"
     ]
    }
   ],
   "source": [
    "# Run Optuna_Trainer\n",
    "\n",
    "n_models = 5\n",
    "\n",
    "for m in range(n_models):\n",
    "    print(f\"Training Model {m}\")\n",
    "    \n",
    "    #Get the necessary information\n",
    "    split = train_test_splits[m]   #There are the same number of splits as there are models\n",
    "    x_train, g_train, y_train, x_validation, g_validation, y_validation, x_test, g_test, y_test = get_wrapper(split, m)\n",
    "    \n",
    "    \n",
    "    # Set random seed\n",
    "    random_seed = m\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    print(device)\n",
    "\n",
    "    # Load pre-trained model\n",
    "    model = GeneInteractionModel(hidden_size=128, num_layers=1).to(device)  # Model\n",
    "    model.load_state_dict(torch.load('models/ontarget/final/model_{}.pt'.format(m % 5)))  # Loads weights, biases from this pre-trained model\n",
    "\n",
    "    # Create a Trainer instance for each model\n",
    "    trainer = Optuna_Trainer(model, x_train, g_train, y_train, x_validation, g_validation, y_validation)\n",
    "\n",
    "    # Execute hyperparameter study\n",
    "    trainer.exec_study()\n",
    "\n",
    "    print(f\"Model {m} complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8fab60-d9d1-4e3a-8801-10f0473362b0",
   "metadata": {},
   "source": [
    "# Fine-tuning with best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "b260ff6c-e267-4972-85fc-f8d4aeead8d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \n",
    "    def __init__(self, model, x_train, g_train, y_train, x_validation, g_validation, y_validation): \n",
    "        self.g_train = g_train\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.g_val = g_validation\n",
    "        self.x_val = x_validation\n",
    "        self.y_val = y_validation\n",
    "        self.model = model\n",
    "\n",
    "        self.patience = 20\n",
    "        self.delta = 1e-4\n",
    "        \n",
    "        if m == 0:\n",
    "            self.lr = 0.01\n",
    "            self.bs = 8\n",
    "            self.ep = 200\n",
    "            \n",
    "        elif m == 1:\n",
    "            self.lr = 0.01\n",
    "            self.bs = 32\n",
    "            self.ep = 100\n",
    "            \n",
    "        elif m == 2:\n",
    "            self.lr = 0.01\n",
    "            self.bs = 8\n",
    "            self.ep = 200  \n",
    "            \n",
    "        elif m == 3:\n",
    "            self.lr = 0.01\n",
    "            self.bs = 32\n",
    "            self.ep = 200\n",
    "          \n",
    "        elif m == 4:\n",
    "            self.lr = 0.005\n",
    "            self.bs = 8\n",
    "            self.ep = 500   \n",
    "            \n",
    "\n",
    "        self.wd = self.lr\n",
    "    \n",
    "        print(m, self.lr, self.bs, self.ep)\n",
    "\n",
    "    def train_model(self):                # Does not take in trial as a parameter because we are no longer testing out different hyperparameters.\n",
    "        \n",
    "        min_loss = None                   # Stores the minimum loss\n",
    "        early_stopping_counter = 0        # Track how many consecutive epochs have occurred without improvement in the validation loss, used to prevent overfitting.\n",
    "        \n",
    "        \n",
    "        train_dataset = GeneFeatureDataset(self.g_train, self.x_train, self.y_train) \n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.bs, shuffle=True, drop_last=True) \n",
    "\n",
    "\n",
    "        val_dataset = GeneFeatureDataset(self.g_val, self.x_val, self.y_val) \n",
    "        val_loader = DataLoader(val_dataset, batch_size=self.bs, shuffle=True)\n",
    "\n",
    "        optimizer = optim.AdamW(self.model.parameters(), lr=self.lr, weight_decay=self.wd) \n",
    "        optimizer.zero_grad()  #Q: Zeroes out gradients?\n",
    "        \n",
    "\n",
    "        criterion = BalancedMSELoss()\n",
    "\n",
    "        print(\"epoch\\ttrain_loss\\tval_loss\")\n",
    "        for epoch in range(self.ep): # self.ep is the number of epochs, so here we are iterating through the epochs\n",
    "            \n",
    "            # Train\n",
    "            self.model.train()  # Sets model in training mode\n",
    "            train_loss = []\n",
    "            train_count = 0\n",
    "    \n",
    "\n",
    "            # Works through each batch of data set up by the train_loader\n",
    "            for i, (g_batch, x_batch, y_batch) in enumerate(train_loader):\n",
    "                g_batch, x_batch, y_batch = g_batch.cuda(), x_batch.cuda(), y_batch.cuda() # If gpu is available, moves tensors to GPU\n",
    "                \n",
    "                g_batch = g_batch.permute((0, 3, 1, 2))\n",
    "                x_batch = x_batch\n",
    "                y_batch = y_batch.reshape(-1, 4)\n",
    "\n",
    "                optimizer.zero_grad()  # Q: Why should I zero the gradient again?\n",
    "\n",
    "                output = self.model(g_batch, x_batch) # Send g and x through the model\n",
    "\n",
    "                total_loss = criterion(output, y_batch) # Calculate the loss between the model output and the measured efficiencies\n",
    "\n",
    "                total_loss.backward()\n",
    "                optimizer.step()  # Applies optimization to update parameters\n",
    "\n",
    "                train_loss.append(x_batch.size(0) * total_loss.detach().cpu().numpy())\n",
    "                train_count += x_batch.size(0)\n",
    "                \n",
    "\n",
    "            train_loss = sum(train_loss) / train_count\n",
    "\n",
    "\n",
    "            # Validation\n",
    "            \n",
    "            self.model.eval()  # Set model in evaluation mode\n",
    "            \n",
    "            val_loss = []\n",
    "            val_count = 0\n",
    "\n",
    "            # Same as with training batches\n",
    "            for i, (g_batch, x_batch, y_batch) in enumerate(val_loader):\n",
    "                g_batch, x_batch, y_batch = g_batch.cuda(), x_batch.cuda(), y_batch.cuda()\n",
    "\n",
    "                g_batch = g_batch.permute((0, 3, 1, 2))\n",
    "                x_batch = x_batch\n",
    "                y_batch = y_batch.reshape(-1, 4)\n",
    "                \n",
    "                output = self.model(g_batch, x_batch)  #Run validation data through model\n",
    "\n",
    "                loss = criterion(output, y_batch)\n",
    "                \n",
    "                val_loss.append(x_batch.size(0) * loss.detach().cpu().numpy())\n",
    "                val_count += x_batch.size(0)\n",
    "\n",
    "            val_loss = sum(val_loss) / val_count\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "            # Summary of training progress\n",
    "            # print(\"{}\\t{:.4f}\\t{:.4f}\".format(epoch, train_loss, val_loss))\n",
    "\n",
    "            \n",
    "\n",
    "            if min_loss is None:\n",
    "                min_loss = val_loss  \n",
    "            elif min_loss - val_loss > self.delta:                    # If the difference between the previous minimum loss and the current validation loss is greater than delta, update values\n",
    "                min_loss = val_loss                                   # Set the new minimum loss to current validation loss\n",
    "                early_stopping_counter = 0                            # Reset to 0, indicating no consecutive epochs with increasing validation loss.\n",
    "            elif min_loss - val_loss < self.delta:                    # No improvement in validation loss\n",
    "                early_stopping_counter += 1                           # Consecutive epoch for which there is no improvement on validation loss\n",
    "                if early_stopping_counter >= self.patience:           # At this point, further training is unlikely to improve/lower validation loss, so break\n",
    "                    break\n",
    "\n",
    "        print(val_loss)\n",
    "        return val_loss  # Returns the minimum validation loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "0a1a7edd-4b4a-4679-b5aa-cbeb46c1c325",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model 0\n",
      "cuda:0\n",
      "0 0.01 8 200\n",
      "epoch\ttrain_loss\tval_loss\n",
      "0.24568200012048086\n",
      "Model 0 complete.\n",
      "Training Model 1\n",
      "cuda:0\n",
      "1 0.01 32 100\n",
      "epoch\ttrain_loss\tval_loss\n",
      "0.7550308108329773\n",
      "Model 1 complete.\n",
      "Training Model 2\n",
      "cuda:0\n",
      "2 0.01 8 200\n",
      "epoch\ttrain_loss\tval_loss\n",
      "0.556384269396464\n",
      "Model 2 complete.\n",
      "Training Model 3\n",
      "cuda:0\n",
      "3 0.01 32 200\n",
      "epoch\ttrain_loss\tval_loss\n",
      "0.40906572341918945\n",
      "Model 3 complete.\n",
      "Training Model 4\n",
      "cuda:0\n",
      "4 0.005 8 500\n",
      "epoch\ttrain_loss\tval_loss\n",
      "0.41006556153297424\n",
      "Model 4 complete.\n"
     ]
    }
   ],
   "source": [
    "# Run Trainer\n",
    "\n",
    "n_models = 5\n",
    "\n",
    "for m in range(n_models):\n",
    "    print(f\"Training Model {m}\")\n",
    "    \n",
    "    x_train, g_train, y_train, x_validation, g_validation, y_validation, x_test, g_test, y_test = get_wrapper(split, m)\n",
    "    \n",
    "    # Set random seed\n",
    "    random_seed = m\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    print(device)\n",
    "\n",
    "    # Load pre-trained model\n",
    "    model = GeneInteractionModel(hidden_size=128, num_layers=1).to(device)  # Model\n",
    "    model.load_state_dict(torch.load('models/ontarget/final/model_{}.pt'.format(m % 5)))  # Loads weights, biases from this pre-trained model\n",
    "\n",
    "    # Create a Trainer instance for each model\n",
    "    trainer = Trainer(model, x_train, g_train, y_train, x_validation, g_validation, y_validation)\n",
    "\n",
    "    # Execute hyperparameter study\n",
    "    trainer.train_model()\n",
    "    \n",
    "    torch.save(model.state_dict(), f'models/endogenous/model_{m}.pt')   # Model has now been updated after training, so store the model in a new folder\n",
    "\n",
    "    print(f\"Model {m} complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb1ebff-e240-49ee-8f98-1fad744ad318",
   "metadata": {},
   "source": [
    "### Now, run test sets through their respective models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "b491800a-06d8-4bad-a632-6d5125b04b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_deepprime_score(df_input, num_model, pe_system='PE2', cell_type='HEK293T'):\n",
    "    \n",
    "\n",
    "    mean = pd.read_csv('../DeepPrime-main/models/DeepPrime/DeepPrime_base/mean.csv', header=None, index_col=0)\n",
    "    std  = pd.read_csv('../DeepPrime-main/models/DeepPrime/DeepPrime_base/std.csv', header=None, index_col=0)\n",
    "\n",
    "    mean = mean.squeeze('columns')\n",
    "    std = std.squeeze('columns')\n",
    "\n",
    "    test_features, test_target = select_cols(test) \n",
    "\n",
    "    g_test = seq_concat(test)\n",
    "    x_test = (test_features - mean) / std\n",
    "\n",
    "    g_test = torch.tensor(g_test, dtype=torch.float32, device=device)\n",
    "    x_test = torch.tensor(x_test.to_numpy(), dtype=torch.float32, device=device)\n",
    "\n",
    "    preds  = []\n",
    "\n",
    "    # Model particular to the test dataset\n",
    "    model = GeneInteractionModel(hidden_size=128, num_layers=1).to(device)\n",
    "    model.load_state_dict(torch.load('models/endogenous/model_{}.pt'.format(0)))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        g, x = g_test, x_test\n",
    "        g = g.permute((0, 3, 1, 2))\n",
    "        pred = model(g, x).detach().cpu().numpy()\n",
    "    preds.append(pred)\n",
    "\n",
    "    # Need this line!!\n",
    "    preds = np.squeeze(np.array(preds))\n",
    "    # preds = np.exp(preds) - 1 # Really am not sure whether I need this line or not, so check with and without, probably\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "30f35dbf-2f09-4f0b-91b2-7c80aec36147",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preprocessing the sequence done 2d\n",
      "(40,) 40 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 1907.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(40,) 40 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 1435.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(40,) 40 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 2094.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(40,) 40 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 1495.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(40,) 40 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 2083.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(40,) 40 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 1511.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(40,) 40 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 2064.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(40,) 40 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 1511.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(39,) 39 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 2206.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n",
      "Start preprocessing the sequence done 2d\n",
      "(39,) 39 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 1542.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed the sequence\n"
     ]
    }
   ],
   "source": [
    "all_test_df = []\n",
    "\n",
    "for i in range(len(train_test_splits)):\n",
    "    \n",
    "    test_indices = train_test_splits[i][2] # This extracts out the test indices \n",
    "    \n",
    "    test = finetune_data.loc[test_indices] # Subset entire data just for the test indices used for this particular model\n",
    "    test = test.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    test['DeepPrime_score'] = calculate_deepprime_score(test, num_model = i)\n",
    "    \n",
    "    all_test_df.append(test)\n",
    "    test.to_csv('Test_' + str(i) + '.csv')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "29d8e87b-0bd2-414b-bd96-f0036e5c139c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene</th>\n",
       "      <th>ID</th>\n",
       "      <th>WT74_On</th>\n",
       "      <th>Edited74_On</th>\n",
       "      <th>PBSlen</th>\n",
       "      <th>RTlen</th>\n",
       "      <th>RT-PBSlen</th>\n",
       "      <th>Edit_pos</th>\n",
       "      <th>Edit_len</th>\n",
       "      <th>RHA_len</th>\n",
       "      <th>...</th>\n",
       "      <th>nGCcnt2</th>\n",
       "      <th>nGCcnt3</th>\n",
       "      <th>fGCcont1</th>\n",
       "      <th>fGCcont2</th>\n",
       "      <th>fGCcont3</th>\n",
       "      <th>MFE3</th>\n",
       "      <th>MFE4</th>\n",
       "      <th>DeepSpCas9_score</th>\n",
       "      <th>Measured_PE_efficiency</th>\n",
       "      <th>DeepPrime_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VEGFA</td>\n",
       "      <td>EDFIG5A_VEGFA_10NT</td>\n",
       "      <td>CTTTGATGTCTGCAGGCCAGATGAGGGCTCCAGATGGCACATTGTC...</td>\n",
       "      <td>xxxxxxxxTCTGCAGGCCAGATGAGTGCTCCAGATGGCACATTGTC...</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>53.658537</td>\n",
       "      <td>-9.4</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>66.789276</td>\n",
       "      <td>25.172570</td>\n",
       "      <td>3.282248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HEK3</td>\n",
       "      <td>FIG2A_PE2_HEK3_10</td>\n",
       "      <td>TTGGGGCCCAGACTGAGCACGTGATGGCAGAGGAAAGGAAGCCCTG...</td>\n",
       "      <td>xxxxxxxxxxxACTGAGCACGAGATGGCAGAxxxxxxxxxxxxxxx...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>63.264858</td>\n",
       "      <td>5.620711</td>\n",
       "      <td>2.074216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HEK3</td>\n",
       "      <td>FIG2A_PE2_HEK3_10</td>\n",
       "      <td>TTGGGGCCCAGACTGAGCACGTGATGGCAGAGGAAAGGAAGCCCTG...</td>\n",
       "      <td>xxxxxxxxCAGACTGAGCACGAGATGGCAGAGGAAAGGxxxxxxxx...</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>52.941176</td>\n",
       "      <td>56.666667</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>63.264858</td>\n",
       "      <td>1.814622</td>\n",
       "      <td>1.749117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RNF2</td>\n",
       "      <td>FIG2A_PE2_RNF2_10</td>\n",
       "      <td>GGCAGTCATCTTAGTCATTACCTGAGGTGTTCGTTGTAACTCATAT...</td>\n",
       "      <td>xxxxxxCATCTTAGTCATTACATGAGGTGTTCGTTGTAAxxxxxxx...</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>38.888889</td>\n",
       "      <td>36.363636</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.229725</td>\n",
       "      <td>5.708600</td>\n",
       "      <td>2.194528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VEGFA</td>\n",
       "      <td>EDFIG5A_VEGFA_10NT</td>\n",
       "      <td>CTTTGATGTCTGCAGGCCAGATGAGGGCTCCAGATGGCACATTGTC...</td>\n",
       "      <td>xxxxxxxxTCTGCAGGCCAGATGAGTGCTCCAGATGGCACATTGTC...</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>53.846154</td>\n",
       "      <td>-8.7</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>66.789276</td>\n",
       "      <td>24.554598</td>\n",
       "      <td>3.366855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>EMX1</td>\n",
       "      <td>FIG2B_EMX1_10</td>\n",
       "      <td>GCCTGAGTCCGAGCAGAAGAAGAAGGGCTCCCATCACATCAACCGG...</td>\n",
       "      <td>xxxxxxxxCCGAGCAGAAGAACAAGGGCTCCCATCxxxxxxxxxxx...</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>53.846154</td>\n",
       "      <td>64.285714</td>\n",
       "      <td>59.259259</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.540627</td>\n",
       "      <td>15.845670</td>\n",
       "      <td>2.735013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>HEK4</td>\n",
       "      <td>FIG2A_PE2_HEK4_10</td>\n",
       "      <td>CGGTGGCACTGCGGCTGGAGGTGGGGGTTAAAGCGGAGACTCTGGT...</td>\n",
       "      <td>xxxxxxxACTGCGGCTGGAGGTTGGGGTTAAAGCxxxxxxxxxxxx...</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>71.428571</td>\n",
       "      <td>46.153846</td>\n",
       "      <td>59.259259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>54.310997</td>\n",
       "      <td>1.758639</td>\n",
       "      <td>1.429103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>VEGFA</td>\n",
       "      <td>EDFIG5A_VEGFA_10NT</td>\n",
       "      <td>CTTTGATGTCTGCAGGCCAGATGAGGGCTCCAGATGGCACATTGTC...</td>\n",
       "      <td>xxxxxxxxTCTGCAGGCCAGATGAGTGCTCCAGATGGCxxxxxxxx...</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>58.823529</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>66.789276</td>\n",
       "      <td>22.536342</td>\n",
       "      <td>3.077928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>DNMT1</td>\n",
       "      <td>EDFIG5B_DNMT1_10NT</td>\n",
       "      <td>TGGGGATTCCTGGTGCCAGAAACAGGGGTGACGGGAGGGCAGAACT...</td>\n",
       "      <td>xxxxxxxxCCTGGTGCCAGAAACAGTGGTGACGGGAGxxxxxxxxx...</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>62.068966</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>65.144363</td>\n",
       "      <td>4.572178</td>\n",
       "      <td>2.014485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>HEK4</td>\n",
       "      <td>FIG2A_PE2_HEK4_10</td>\n",
       "      <td>CGGTGGCACTGCGGCTGGAGGTGGGGGTTAAAGCGGAGACTCTGGT...</td>\n",
       "      <td>xxxxxxCACTGCGGCTGGAGGTTGGGGTTAAAGCxxxxxxxxxxxx...</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>46.153846</td>\n",
       "      <td>60.714286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>54.310997</td>\n",
       "      <td>1.395180</td>\n",
       "      <td>1.186565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gene                  ID  \\\n",
       "0   VEGFA  EDFIG5A_VEGFA_10NT   \n",
       "1    HEK3   FIG2A_PE2_HEK3_10   \n",
       "2    HEK3   FIG2A_PE2_HEK3_10   \n",
       "3    RNF2   FIG2A_PE2_RNF2_10   \n",
       "4   VEGFA  EDFIG5A_VEGFA_10NT   \n",
       "..    ...                 ...   \n",
       "34   EMX1       FIG2B_EMX1_10   \n",
       "35   HEK4   FIG2A_PE2_HEK4_10   \n",
       "36  VEGFA  EDFIG5A_VEGFA_10NT   \n",
       "37  DNMT1  EDFIG5B_DNMT1_10NT   \n",
       "38   HEK4   FIG2A_PE2_HEK4_10   \n",
       "\n",
       "                                              WT74_On  \\\n",
       "0   CTTTGATGTCTGCAGGCCAGATGAGGGCTCCAGATGGCACATTGTC...   \n",
       "1   TTGGGGCCCAGACTGAGCACGTGATGGCAGAGGAAAGGAAGCCCTG...   \n",
       "2   TTGGGGCCCAGACTGAGCACGTGATGGCAGAGGAAAGGAAGCCCTG...   \n",
       "3   GGCAGTCATCTTAGTCATTACCTGAGGTGTTCGTTGTAACTCATAT...   \n",
       "4   CTTTGATGTCTGCAGGCCAGATGAGGGCTCCAGATGGCACATTGTC...   \n",
       "..                                                ...   \n",
       "34  GCCTGAGTCCGAGCAGAAGAAGAAGGGCTCCCATCACATCAACCGG...   \n",
       "35  CGGTGGCACTGCGGCTGGAGGTGGGGGTTAAAGCGGAGACTCTGGT...   \n",
       "36  CTTTGATGTCTGCAGGCCAGATGAGGGCTCCAGATGGCACATTGTC...   \n",
       "37  TGGGGATTCCTGGTGCCAGAAACAGGGGTGACGGGAGGGCAGAACT...   \n",
       "38  CGGTGGCACTGCGGCTGGAGGTGGGGGTTAAAGCGGAGACTCTGGT...   \n",
       "\n",
       "                                          Edited74_On  PBSlen  RTlen  \\\n",
       "0   xxxxxxxxTCTGCAGGCCAGATGAGTGCTCCAGATGGCACATTGTC...      13     28   \n",
       "1   xxxxxxxxxxxACTGAGCACGAGATGGCAGAxxxxxxxxxxxxxxx...      10     10   \n",
       "2   xxxxxxxxCAGACTGAGCACGAGATGGCAGAGGAAAGGxxxxxxxx...      13     17   \n",
       "3   xxxxxxCATCTTAGTCATTACATGAGGTGTTCGTTGTAAxxxxxxx...      15     18   \n",
       "4   xxxxxxxxTCTGCAGGCCAGATGAGTGCTCCAGATGGCACATTGTC...      13     26   \n",
       "..                                                ...     ...    ...   \n",
       "34  xxxxxxxxCCGAGCAGAAGAACAAGGGCTCCCATCxxxxxxxxxxx...      13     14   \n",
       "35  xxxxxxxACTGCGGCTGGAGGTTGGGGTTAAAGCxxxxxxxxxxxx...      14     13   \n",
       "36  xxxxxxxxTCTGCAGGCCAGATGAGTGCTCCAGATGGCxxxxxxxx...      13     17   \n",
       "37  xxxxxxxxCCTGGTGCCAGAAACAGTGGTGACGGGAGxxxxxxxxx...      13     16   \n",
       "38  xxxxxxCACTGCGGCTGGAGGTTGGGGTTAAAGCxxxxxxxxxxxx...      15     13   \n",
       "\n",
       "    RT-PBSlen  Edit_pos  Edit_len  RHA_len  ...  nGCcnt2  nGCcnt3   fGCcont1  \\\n",
       "0          41         5         1       23  ...       14       22  61.538462   \n",
       "1          20         1         1        9  ...        5       11  60.000000   \n",
       "2          30         1         1       16  ...        9       17  61.538462   \n",
       "3          33         1         1       17  ...        7       12  33.333333   \n",
       "4          39         5         1       21  ...       13       21  61.538462   \n",
       "..        ...       ...       ...      ...  ...      ...      ...        ...   \n",
       "34         27         1         1       13  ...        9       16  53.846154   \n",
       "35         27         2         1       11  ...        6       16  71.428571   \n",
       "36         30         5         1       12  ...       10       18  61.538462   \n",
       "37         29         5         1       11  ...       10       18  61.538462   \n",
       "38         28         2         1       11  ...        6       17  73.333333   \n",
       "\n",
       "     fGCcont2   fGCcont3  MFE3  MFE4  DeepSpCas9_score  \\\n",
       "0   50.000000  53.658537  -9.4  -3.3         66.789276   \n",
       "1   50.000000  55.000000  -0.2  -0.7         63.264858   \n",
       "2   52.941176  56.666667  -0.6  -0.7         63.264858   \n",
       "3   38.888889  36.363636  -1.6   0.0         52.229725   \n",
       "4   50.000000  53.846154  -8.7  -3.3         66.789276   \n",
       "..        ...        ...   ...   ...               ...   \n",
       "34  64.285714  59.259259  -4.4   0.0         69.540627   \n",
       "35  46.153846  59.259259   0.0  -3.5         54.310997   \n",
       "36  58.823529  60.000000  -8.2  -3.3         66.789276   \n",
       "37  62.500000  62.068966  -1.9  -1.6         65.144363   \n",
       "38  46.153846  60.714286   0.0  -3.5         54.310997   \n",
       "\n",
       "    Measured_PE_efficiency  DeepPrime_score  \n",
       "0                25.172570         3.282248  \n",
       "1                 5.620711         2.074216  \n",
       "2                 1.814622         1.749117  \n",
       "3                 5.708600         2.194528  \n",
       "4                24.554598         3.366855  \n",
       "..                     ...              ...  \n",
       "34               15.845670         2.735013  \n",
       "35                1.758639         1.429103  \n",
       "36               22.536342         3.077928  \n",
       "37                4.572178         2.014485  \n",
       "38                1.395180         1.186565  \n",
       "\n",
       "[199 rows x 30 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate all the test data frames\n",
    "\n",
    "concatenated = pd.concat(all_test_df)\n",
    "concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "dc5fc344-5ff4-4cfd-ac13-e24420ae629a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "concatenated.to_csv('FineTuned_Endogenous_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "62e258c6-2a3b-4ccb-8da5-670e0cbf9786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "4eab0d3e-90fa-4727-b013-27b690f5cf9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8078624790216843 0.8620989352475041\n"
     ]
    }
   ],
   "source": [
    "x = concatenated['Measured_PE_efficiency']\n",
    "y = concatenated['DeepPrime_score']\n",
    "                           \n",
    "pearson_corr, pearson_p_value = pearsonr(x, y)\n",
    "spearman_corr, spearman_p_value = spearmanr(x, y)\n",
    "                           \n",
    "\n",
    "print(pearson_corr, spearman_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c6827784-00d9-4ede-9565-c4aae672be60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, y, s= 10)\n",
    "\n",
    "# for gene, color in color_mapping.items():\n",
    "#     plt.scatter(x[df_input['Gene'] == gene], y[df_input['Gene'] == gene], \n",
    "#                 s=10, c=color, label=gene)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Measured_Editing_Frequency')\n",
    "plt.ylabel('DeepPrime_Predicted_Efficiency')\n",
    "plt.title('Endogenous Measured vs. Predicted Efficiencies')\n",
    "# plt.legend(title='Gene', loc = 'lower right')\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), color='red', label='Regression Line (Pearson)')\n",
    "\n",
    "\n",
    "plt.text(min(x), max(y), f\"r: {pearson_corr:.2f}\", fontsize=10)\n",
    "\n",
    "# Annotate Spearman correlation coefficient\n",
    "plt.text(min(x), max(y)-0.2, f\"R: {spearman_corr:.2f}\", fontsize=10)\n",
    "\n",
    "plt.text(min(x), max(y)-0.4, \"n = \"+ str(len(concatenated)), fontsize=10)\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepPrime",
   "language": "python",
   "name": "genet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
